{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49f77ae",
   "metadata": {},
   "source": [
    "# Finding Similar Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4be83",
   "metadata": {},
   "source": [
    "## 1.\tIntroduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f101114",
   "metadata": {},
   "source": [
    "### Frequent pair of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e32af",
   "metadata": {},
   "source": [
    "- Extract a list of the authors or editors per publication from the ACL Anthology dataset (https://aclanthology.org/) and create baskets and perform a search on the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30320fa",
   "metadata": {},
   "source": [
    "1. Find the frequent pair of items (2-tuples) using the naïve, A-priori and PCY algorithms. For each of these compare the time of execution and results for supports s=10, 50, 100. Comment your results. \n",
    "\n",
    "2. For the PCY algorithm, create up to 5 compact hash tables. What is  the difference in results and time of execution for 1,2,3,4 and 5 tables? Comment your results.\n",
    "\n",
    "3. Find the final list of k-frequent items (k-tuples) for k=3 and 4. Experiment a bit and describe the best value for the support in each case. *Warning*: You can use any of the three algorithms, but be careful, because the algorithm can take too long if you don't chose it properly (well, basically don't use the naïve approach ;)).\n",
    "\n",
    "4. Using one of the results of the previous items, for one k (k=2 or 3) find the possible clusters using the 1-NN criteria. Comment your results.\n",
    "\n",
    "> 1-NN means that if you have a tuple {A,B,C} and {C,E,F} then because they share one element {C}, then they belong to the same cluster  {A,B,C,E,F}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa504e",
   "metadata": {},
   "source": [
    "-\tDefine all and only used package imports below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb367a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alext\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests # to download the dataset\n",
    "import gzip\n",
    "import shutil # to extract the gz file\n",
    "import re # for text cleaning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from nltk.corpus import stopwords # calculation of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97e789",
   "metadata": {},
   "source": [
    "## 2.\tELT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039ec36",
   "metadata": {},
   "source": [
    "### Extract, Load and Transform of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3f8b0",
   "metadata": {},
   "source": [
    "- In your code data should be retrieved from an online source, NOT from your local drive, otherwise, nobody can run your code without additional effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac08ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data \n",
    "url = 'https://aclanthology.org/anthology+abstracts.bib.gz'\n",
    "filename = url.split(\"/\")[-1]\n",
    "with open(filename, \"wb\") as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)\n",
    "\n",
    "# Extract the gz file\n",
    "with gzip.open('anthology+abstracts.bib.gz', 'rb') as f_in:\n",
    "    with open('anthology+abstracts.bib', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd886656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74739 rows of authors were found in the file.\n"
     ]
    }
   ],
   "source": [
    "# Find all the rows in the file that contain an abstract and laod the text to a list\n",
    "authors = []\n",
    "with open(\"anthology+abstracts.bib\", \"r\",encoding=\"UTF-8\") as f:\n",
    "    s = f.readlines()\n",
    "    for x in s:\n",
    "        #Create a function for the if statement below?\n",
    "        if x.__contains__('author ='):\n",
    "            start = x.find('    author = \"') + len('    author = \"')\n",
    "            end = x.find('\",')\n",
    "            substring = x[start:end]\n",
    "            authors.append(substring)\n",
    "        if x.__contains__('editor ='):\n",
    "            start = x.find('    editor = \"') + len('    editor = \"')\n",
    "            end = x.find('\",')\n",
    "            substring = x[start:end]\n",
    "            authors.append(substring)\n",
    "            authors.append(\"\")\n",
    "    f.close()\n",
    "    f.close()\n",
    "\n",
    "print(\"{} rows of authors were found in the file.\".format(len(authors)))\n",
    "#the issue here is that only the first row after author/editor is stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f7b1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above is wrong, perhaps some solution like the one here: \n",
    "# https://stackoverflow.com/questions/21421060/read-a-file-and-extract-lines-between-two-lines-of-specific-text-in-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ace185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mostafazadeh Davani, Aida  and',\n",
       " '',\n",
       " 'Singh, Sumer  and',\n",
       " 'Hahn, Vanessa  and',\n",
       " 'Caselli, Tommaso  and',\n",
       " 'Kirk, Hannah  and',\n",
       " 'Kivlichan, Ian  and',\n",
       " 'Caselli, Tommaso  and',\n",
       " 'Niraula, Nobal B.  and',\n",
       " 'Fortuna, Paula  and',\n",
       " 'Manerba, Marta Marchiori  and',\n",
       " 'Mostafazadeh Davani, Aida  and',\n",
       " 'Zad, Samira  and',\n",
       " 'Chuang, Yung-Sung  and',\n",
       " 'Aksenov, Dmitrii  and',\n",
       " 'Sodhi, Ravsimar  and',\n",
       " 'Xenos, Alexandros  and',\n",
       " 'Salawu, Semiu  and',\n",
       " 'Risch, Julian  and',\n",
       " 'Trujillo, Milo  and',\n",
       " 'Shvets, Alexander  and',\n",
       " 'Bertaglia, Thales  and',\n",
       " 'Mathias, Lambert  and',\n",
       " 'Aggarwal, Piush  and',\n",
       " 'Zia, Haris Bin  and',\n",
       " 'Kougia, Vasiliki  and',\n",
       " 'Xu, Wei  and',\n",
       " '',\n",
       " 'Dadu, Tanvi  and',\n",
       " 'Olsen, Benjamin  and',\n",
       " '{H{\\\\\"a}m{\\\\\"a}l{\\\\\"a}inen, Mika  and',\n",
       " 'Lei, Yanfei  and',\n",
       " 'Tran Phu, Minh  and',\n",
       " 'Le, Duong  and',\n",
       " 'Cho, Won Ik  and',\n",
       " 'Feucht, Malte  and',\n",
       " 'Higashiyama, Shohei  and',\n",
       " 'Cheong, Sik Feng  and',\n",
       " 'Chen, Shuguang  and',\n",
       " 'Plepi, Joan  and',\n",
       " 'Gao, Mengyi  and',\n",
       " 'Lent, Heather  and',\n",
       " 'Srivastava, Vivek  and',\n",
       " 'Aghajani, MohammadMahdi  and',\n",
       " 'Bogensperger, Johannes  and',\n",
       " 'Pratapa, Adithya  and',\n",
       " 'Fu, Xue-Yong  and',\n",
       " 'Deng, Yang  and',\n",
       " 'Murayama, Taichi  and',\n",
       " \"Rosales N{\\\\'u}{\\\\~n}ez, Jos{\\\\'e} Carlos  and\",\n",
       " \"Rosales N{\\\\'u}{\\\\~n}ez, Jos{\\\\'e} Carlos  and\",\n",
       " '{Kruspe, Anna  and',\n",
       " 'Mirshekari, Mostafa  and',\n",
       " 'Scaboro, Simone  and',\n",
       " \"Jacqmin, L{\\\\'e}o  and\",\n",
       " 'Spiliopoulou, Evangelia  and',\n",
       " 'Shim, Heereen  and',\n",
       " 'Li, Jinfen  and',\n",
       " 'Soper, Elizabeth  and',\n",
       " '{Vahtola, Teemu  and',\n",
       " 'Bhardwaj, Shivendra  and',\n",
       " 'Clark, Thomas  and',\n",
       " 'Ghosh, Sayan  and',\n",
       " 'Bertsch, Amanda  and',\n",
       " 'Novikova, Jekaterina',\n",
       " \"N{\\\\'a}plava, Jakub  and\",\n",
       " 'Oliveira dos Santos, Gabriel  and',\n",
       " 'Davidson, Sam  and',\n",
       " 'Kashefi, Omid  and',\n",
       " 'Mishra, Shubhanshu  and',\n",
       " 'Lee, Jian Yi David  and',\n",
       " 'Chinta, Abhinav  and',\n",
       " 'Lee, Sangah  and',\n",
       " 'Straka, Milan  and',\n",
       " 'Riabi, Arij  and',\n",
       " 'Priyanshu, Aman  and',\n",
       " 'Guo, Yanzhu  and',\n",
       " 'Ehara, Yo',\n",
       " 'Kubal, Divesh  and',\n",
       " 'Scherrer, Yves  and',\n",
       " 'Bucur, Ana-Maria  and',\n",
       " 'Samuel, David  and',\n",
       " '{van der Goot, Rob  and',\n",
       " 'van der Goot, Rob',\n",
       " 'Barrault, Loic  and',\n",
       " '',\n",
       " 'Akhbardeh, Farhad  and',\n",
       " 'Wenzek, Guillaume  and',\n",
       " 'Bei, Chao  and',\n",
       " 'Chen, Pinzhen  and',\n",
       " 'Erdmann, Grant  and',\n",
       " 'Escolano, Carlos  and',\n",
       " 'Gebauer, Petr  and',\n",
       " 'Hendy, Amr  and',\n",
       " \"S{\\\\'\\\\i}monarson, Haukur Barri  and\",\n",
       " 'Koszowski, Miko{\\\\l}aj  and',\n",
       " 'Le, Giang  and',\n",
       " 'Li, Zuchao  and',\n",
       " 'Martinez, Ander',\n",
       " 'Nowakowski, Artur  and',\n",
       " 'Oravecz, Csaba  and',\n",
       " 'Pal, Proyag  and',\n",
       " 'Qian, Lihua  and',\n",
       " 'Subramanian, Sandeep  and',\n",
       " 'Tran, Chau  and',\n",
       " 'Wang, Longyue  and',\n",
       " 'Wei, Daimeng  and',\n",
       " 'Xu, Jitao  and',\n",
       " 'Zeng, Xianfeng  and',\n",
       " 'Zeng, Hui',\n",
       " 'Zhao, Shiyu  and',\n",
       " 'Zhou, Shuhan  and',\n",
       " 'Adebara, Ife  and',\n",
       " 'Canals, Miguel  and',\n",
       " 'Laskar, Sahinur Rahman  and',\n",
       " 'Mujadia, Vandan  and',\n",
       " 'Rapp, Reinhard',\n",
       " 'Saldanha, Richard  and',\n",
       " 'Yadav, Saumitra  and',\n",
       " 'Oh, Shinhyeok  and',\n",
       " 'Sharma, Abhishek  and',\n",
       " 'Guo, Hangcheng  and',\n",
       " 'Li, Zongyao  and',\n",
       " 'Liu, Huan  and',\n",
       " 'Mhaskar, Shivam  and',\n",
       " 'Park, Jeonghyeok  and',\n",
       " 'Chen, Wei-Rui  and',\n",
       " 'Jon, Josef  and',\n",
       " 'Kharitonova, Ksenia  and',\n",
       " 'Tchistiakova, Svetlana  and',\n",
       " 'Yang, Han  and',\n",
       " 'Bandyopadhyay, Saptarashmi  and',\n",
       " 'Budiwati, Sari Dewi  and',\n",
       " 'Emezue, Chris Chinenye  and',\n",
       " 'Lai, Wen  and',\n",
       " 'Liao, Baohao  and',\n",
       " 'Liu, Danni  and',\n",
       " 'Sutawika, Lintang  and',\n",
       " 'Xie, Wanying  and',\n",
       " 'Yang, Jian  and',\n",
       " 'Yu, Zhengzhe  and',\n",
       " 'Knowles, Rebecca',\n",
       " 'Kocmi, Tom  and',\n",
       " \"Krubi{\\\\'n}ski, Mateusz  and\",\n",
       " 'Hanna, Michael  and',\n",
       " 'Mirzakhalov, Jamshidbek  and',\n",
       " 'Troles, Jonas-Dario  and',\n",
       " 'Berard, Alexandre',\n",
       " 'Castilho, Sheila  and',\n",
       " 'Cooper Stickland, Asa  and',\n",
       " 'Del, Maksym  and',\n",
       " 'Hangya, Viktor  and',\n",
       " 'Kanojia, Diptesh  and',\n",
       " 'Heafield, Kenneth  and',\n",
       " 'Alam, Md Mahfuz Ibn  and',\n",
       " 'Yeganova, Lana  and',\n",
       " 'Specia, Lucia  and',\n",
       " \"Libovick{\\\\'y}, Jind{\\\\v{r}}ich  and\",\n",
       " 'Freitag, Markus  and',\n",
       " 'Behnke, Maximiliana  and',\n",
       " 'Shang, Hengchao  and',\n",
       " 'Wang, Chenglong  and',\n",
       " 'Wu, Kaixin  and',\n",
       " 'Ailem, Melissa  and',\n",
       " 'Bak, Yunju  and',\n",
       " 'Ballier, Nicolas  and',\n",
       " 'Bergmanis, Toms  and',\n",
       " 'Jon, Josef  and',\n",
       " 'Molchanov, Alexander  and',\n",
       " 'Pham, Minh Quang  and',\n",
       " 'Wang, Ke  and',\n",
       " 'Naz, Sumbal  and',\n",
       " 'Rafieian, Bardia  and',\n",
       " 'Wang, Weixuan  and',\n",
       " 'Wang, Xing  and',\n",
       " 'Yang, Hao  and',\n",
       " 'Bi{\\\\c{c}}ici, Ergun',\n",
       " 'Chen, Yimeng  and',\n",
       " 'Chowdhury, Shaika  and',\n",
       " 'Ding, Shuoyang  and',\n",
       " '{Geigle, Gregor  and',\n",
       " 'Heo, Dam  and',\n",
       " 'Jiang, Genze  and',\n",
       " 'Lim, Seunghyun  and',\n",
       " 'Rubino, Raphael  and',\n",
       " 'Wang, Jiayi  and',\n",
       " 'Yankovskaya, Lisa  and',\n",
       " 'Zerva, Chrysoula  and',\n",
       " 'Atrio, {\\\\`A}lex R.  and',\n",
       " '{Edman, Lukas  and',\n",
       " \"Libovick{\\\\'y}, Jind{\\\\v{r}}ich  and\",\n",
       " 'Khatri, Jyotsana  and',\n",
       " 'Knowles, Rebecca  and',\n",
       " 'Zhang, Meng  and',\n",
       " 'Han, Lifeng  and',\n",
       " \"Krubi{\\\\'n}ski, Mateusz  and\",\n",
       " 'Rei, Ricardo  and',\n",
       " 'Stefanik, Michal  and',\n",
       " 'Takahashi, Kosuke  and',\n",
       " 'Wan, Yu  and',\n",
       " '{Macketanz, Vivien  and',\n",
       " 'Behnke, Maximiliana  and',\n",
       " 'Hu, Junjie  and',\n",
       " 'Kumar, Gaurav  and',\n",
       " 'Han, HyoJung  and',\n",
       " 'Kano, Yasumasa  and',\n",
       " 'Hwang, Yongkeun  and',\n",
       " 'Varis, Erika  and',\n",
       " '',\n",
       " 'Dossou, Bonaventure F. P.  and',\n",
       " 'Gharbi, Slim  and',\n",
       " '{H{\\\\\"a}m{\\\\\"a}l{\\\\\"a}inen, Mika  and',\n",
       " 'Podin{\\\\u{a}}, Ioana R.  and',\n",
       " 'Destaw, Tadesse  and',\n",
       " 'Nakazawa, Toshiaki  and',\n",
       " '',\n",
       " 'Nakazawa, Toshiaki  and',\n",
       " 'Mino, Hideya  and',\n",
       " 'Chousa, Katsuki  and',\n",
       " 'Li, Zuchao  and',\n",
       " 'Kondo, Seiichiro  and',\n",
       " 'Hlaing, Zar Zar  and',\n",
       " 'Thu, Ye Kyaw  and',\n",
       " 'Imamura, Kenji  and',\n",
       " 'Susanto, Raymond Hendy  and',\n",
       " 'Park, Chanjun  and',\n",
       " 'Ri, Ryokan  and',\n",
       " 'Yamakoshi, Takahiro  and',\n",
       " 'Kim, Hwichan  and',\n",
       " 'Stribi{\\\\.z}ew, Wiktor  and',\n",
       " 'Park, Heesoo  and',\n",
       " 'Parida, Shantipriya  and',\n",
       " 'Laskar, Sahinur Rahman  and',\n",
       " 'Gain, Baban  and',\n",
       " 'Gupta, Kshitij  and',\n",
       " 'Zhao, Yuting  and',\n",
       " 'Dhar, Prajit  and',\n",
       " 'Aralikatte, Rahul  and',\n",
       " 'Dabre, Raj  and',\n",
       " 'Aralikatte, Rahul  and',\n",
       " 'Kumar, Sourav  and',\n",
       " 'Khatri, Jyotsana  and',\n",
       " 'Dobrowolski, Adam  and',\n",
       " 'Mhaskar, Shivam  and',\n",
       " 'Appicharla, Ramakrishna  and',\n",
       " 'Vegi, Pavanpankaj  and',\n",
       " 'De Clercq, Orphee  and',\n",
       " '',\n",
       " 'Xiang, Tong  and',\n",
       " 'Kerz, Elma  and',\n",
       " 'Lindow, Mike  and',\n",
       " 'Akula, Ramya  and',\n",
       " 'Troiano, Enrica  and',\n",
       " 'Dayanik, Erenay  and',\n",
       " 'Lamprinidis, Sotiris  and',\n",
       " 'Bianchi, Federico  and',\n",
       " 'Singh, Aaditya  and',\n",
       " 'Tafreshi, Shabnam  and',\n",
       " 'Kulkarni, Atharva  and',\n",
       " 'Mundra, Jay  and',\n",
       " 'Rao Vijjini, Anvesh  and',\n",
       " 'Sourav, Soumya  and',\n",
       " 'Van Hee, Cynthia  and',\n",
       " 'Markov, Ilia  and',\n",
       " 'Hofmann, Jan  and',\n",
       " 'Grimminger, Lara  and',\n",
       " 'Conforti, Costanza  and',\n",
       " 'Ali, Wazir  and',\n",
       " 'Wadhawan, Anshul  and',\n",
       " 'Kaminska, Olha  and',\n",
       " 'Kulkarni, Atharva  and',\n",
       " 'Edmonds, Darren  and',\n",
       " 'Guellil, Imane  and',\n",
       " 'Culnan, John  and',\n",
       " 'De Bruyne, Luna  and',\n",
       " 'Vettigli, Giuseppe  and',\n",
       " 'Fornaciari, Tommaso  and',\n",
       " 'Butala, Yash  and',\n",
       " 'Habash, Nizar  and',\n",
       " '',\n",
       " 'Abdelali, Ahmed  and',\n",
       " 'Abdul-Mageed, Muhammad  and',\n",
       " 'Abu Farha, Ibrahim  and',\n",
       " 'Albilali, Eman  and',\n",
       " 'Alharbi, Alaa  and',\n",
       " 'Alyafeai, Zaid  and',\n",
       " 'Hakami, Shatha Ali A.  and',\n",
       " 'Haouari, Fatima  and',\n",
       " 'Haouari, Fatima  and',\n",
       " 'Inoue, Go  and',\n",
       " 'Khallaf, Nouran  and',\n",
       " 'Majadly, Muhammad  and',\n",
       " 'Mubarak, Hamdy  and',\n",
       " 'Mubarak, Hamdy  and',\n",
       " 'Mubarak, Hamdy  and',\n",
       " 'Mulki, Hala  and',\n",
       " 'Naous, Tarek  and',\n",
       " 'Seelawi, Haitham  and',\n",
       " 'Alsaleh, Abdullah  and',\n",
       " 'Antoun, Wissam  and',\n",
       " 'Antoun, Wissam  and',\n",
       " 'Asaad, Al-Ahmadgaid',\n",
       " 'Eryani, Fadhl  and',\n",
       " 'Esmeir, Saher',\n",
       " 'Fourati, Chayma  and',\n",
       " 'Sheikh Ali, Zien  and',\n",
       " 'Nguyen, Minh Van  and',\n",
       " 'Abdul-Mageed, Muhammad  and',\n",
       " 'AlKhamissi, Badr  and',\n",
       " 'Althobaiti, Maha J.',\n",
       " 'El Mekki, Abdellah  and',\n",
       " 'Issa, Elsayed  and',\n",
       " 'Lichouri, Mohamed  and',\n",
       " 'Nayel, Hamada  and',\n",
       " 'Wadhawan, Anshul',\n",
       " 'Abu Farha, Ibrahim  and',\n",
       " 'Abdel-Salam, Reem',\n",
       " 'Abuzayed, Abeer  and',\n",
       " 'Alharbi, Abdullah I.  and',\n",
       " 'Bashmal, Laila  and',\n",
       " '{Ghoul, Dhaou  and',\n",
       " 'El Mahdaouy, Abdelkader  and',\n",
       " 'Elgabry, Hazem  and',\n",
       " 'Faraj, Dalya  and',\n",
       " 'Gaanoun, Kamel  and',\n",
       " 'Hengle, Amey  and',\n",
       " 'Husain, Fatemah  and',\n",
       " 'Israeli, Abraham  and',\n",
       " 'Lichouri, Mohamed  and',\n",
       " 'Naski, Malek  and',\n",
       " 'Nayel, Hamada  and',\n",
       " 'Song, Bingyan  and',\n",
       " 'Wadhawan, Anshul',\n",
       " 'Cangea, C{\\\\u{a}}t{\\\\u{a}}lina  and',\n",
       " '',\n",
       " '{Zampieri, Marcos  and',\n",
       " '',\n",
       " 'Chakravarthi, Bharathi Raja  and',\n",
       " 'Khusainova, Albina  and',\n",
       " 'Frassinelli, Diego  and',\n",
       " 'Dunn, Jonathan',\n",
       " 'Lameris, Harm  and',\n",
       " 'Aly, Rami  and',\n",
       " 'Bhatia, Kushagra  and',\n",
       " \"Haas, Ren{\\\\'e}  and\",\n",
       " 'Jauhiainen, Tommi  and',\n",
       " 'Mihaela, Gaman  and',\n",
       " 'Bestgen, Yves',\n",
       " 'Ceolin, Andrea',\n",
       " 'Zaharia, George-Eduard  and',\n",
       " 'Jauhiainen, Tommi  and',\n",
       " 'Bernier-Colborne, Gabriel  and',\n",
       " 'Scherrer, Yves  and',\n",
       " 'Roth, Michael  and',\n",
       " '',\n",
       " '{Kurfal{\\\\i}, Murathan  and',\n",
       " 'Bexte, Marie  and',\n",
       " 'Eisenstadt, Roy  and',\n",
       " 'Roth, Michael  and',\n",
       " 'Ma, Weicheng  and',\n",
       " 'Stengel-Eskin, Elias  and',\n",
       " 'Ruby, Ahmed  and',\n",
       " 'Wiriyathammabhum, Peratham',\n",
       " 'de Lhoneux, Miryam  and',\n",
       " '',\n",
       " 'Cecchini, Flavio Massimiliano',\n",
       " 'Coto-Solano, Rolando  and',\n",
       " 'Evang, Kilian  and',\n",
       " 'Farris, Adam  and',\n",
       " '{Hassert, Na{\\\\\"\\\\i}ma  and',\n",
       " '{H{\\\\\"o}hn, Georg F.K.},',\n",
       " 'Janssen, Maarten',\n",
       " 'Kalpakchi, Dmytro  and',\n",
       " 'Lapalme, Guy',\n",
       " 'Lusito, Stefano  and',\n",
       " 'Derin, Mehmet Oguz  and',\n",
       " 'Omura, Mai  and',\n",
       " 'Rueter, Jack  and',\n",
       " 'Schneider, Nathan  and',\n",
       " 'Zeman, Daniel',\n",
       " 'Pruksachatkun, Yada  and',\n",
       " '',\n",
       " 'Tang, Zheng  and',\n",
       " 'Azarpanah, Hossein  and',\n",
       " 'Feyisetan, Oluwaseyi  and',\n",
       " 'Misra, Amita  and',\n",
       " 'Vadrevu, Samhita  and',\n",
       " 'Matthews, Abigail  and',\n",
       " 'Kumar, Sawan  and',\n",
       " 'Idahl, Maximilian  and',\n",
       " 'Mitkov, Ruslan  and',\n",
       " '',\n",
       " 'Sklavounou, Elsa',\n",
       " 'Villani, Rossana',\n",
       " 'Corpas Pastor, Gloria',\n",
       " 'Bowker, Lynne',\n",
       " 'Mouratidis, Despoina  and',\n",
       " 'Saadany, Hadeel  and',\n",
       " 'Saina, Francesco',\n",
       " 'Murgu, Dora',\n",
       " 'Cariello, Maria Carmela  and',\n",
       " 'Hatami, Ali  and',\n",
       " 'Rivera-Trigueros, Irene  and',\n",
       " 'Rodriguez, Susana  and',\n",
       " 'Roelofsen, Floris  and',\n",
       " 'Ben Milad, Khaled',\n",
       " \"Bell{\\\\'e}s-Calvera, Luc{\\\\'\\\\i}a  and\",\n",
       " \"Venturott, L{\\\\'\\\\i}gia  and\",\n",
       " 'Eschenbruecher, Anne',\n",
       " \"Caro Quintana, Roc{\\\\'\\\\i}o\",\n",
       " 'Escribe, Marie  and',\n",
       " 'Bestgen, Yves',\n",
       " \"Ram{\\\\'\\\\i}rez-S{\\\\'a}nchez, Gema  and\",\n",
       " 'Gene, Viveta',\n",
       " 'Papadopoulou, Martha Maria  and',\n",
       " 'Jimenez-Crespo, Miguel A.',\n",
       " 'Charalampidou, Parthena',\n",
       " '{Dakota, Daniel  and',\n",
       " '',\n",
       " 'Alves, Diego  and',\n",
       " 'Biagetti, Erica',\n",
       " '{Grobol, Lo{\\\\\"\\\\i}c  and',\n",
       " 'Kahane, Sylvain  and',\n",
       " 'Kahane, Sylvain  and',\n",
       " 'Krishnamurthy, Parameswari  and',\n",
       " '{M{\\\\\"u}ller-Eberstein, Max  and',\n",
       " 'Sampanis, Konstantinos  and',\n",
       " 'van der Goot, Rob  and',\n",
       " 'Yuan, Jingting  and',\n",
       " 'Panchenko, Alexander  and',\n",
       " '',\n",
       " 'Jin, Yiping  and',\n",
       " '{Schmitt, Martin  and',\n",
       " 'Baumgartner, Matthias  and',\n",
       " 'Phung, Duy  and',\n",
       " 'Zeng, Qi  and',\n",
       " 'Gao, Yanjun  and',\n",
       " 'Wang, Luyu  and',\n",
       " 'Hou, Xiaochen  and',\n",
       " 'Papagiannopoulou, Eirini  and',\n",
       " 'Schwarzer, Max  and',\n",
       " 'Zhao, Jinman  and',\n",
       " 'BehnamGhader, Parishad  and',\n",
       " 'Dutta, Sanghamitra  and',\n",
       " 'Weber, Sabine  and',\n",
       " 'Jha, Rishi  and',\n",
       " 'Fujinuma, Yoshinari  and',\n",
       " 'Thayaparan, Mokanarangan  and',\n",
       " 'Pan, Chunguang  and',\n",
       " 'Xiang, Yuejia  and',\n",
       " 'Vivek Kalyan, Sureshkumar  and',\n",
       " 'Jurgens, David  and',\n",
       " '',\n",
       " '{Saini, Rajkumar  and',\n",
       " 'Artemova, Ekaterina  and',\n",
       " 'Baglini, Rebekah  and',\n",
       " 'Amblard, Maxime  and',\n",
       " 'Hiippala, Tuomo',\n",
       " 'Friedrich, Annemarie  and',\n",
       " 'Messina, Lucio  and',\n",
       " 'Delbrouck, Jean-Benoit',\n",
       " 'Plank, Barbara',\n",
       " 'Jurgens, David',\n",
       " 'Manning, Emma  and',\n",
       " 'Smith, Ronnie',\n",
       " 'Agirrezabal, Manex',\n",
       " 'Madureira, Brielen',\n",
       " 'Poliak, Adam  and',\n",
       " 'Taneja, Sanya  and',\n",
       " 'Durrett, Greg  and',\n",
       " 'Gaddy, David  and',\n",
       " 'Jurgens, David',\n",
       " 'Foster, Jennifer  and',\n",
       " 'Kennington, Casey',\n",
       " 'Eisenstein, Jacob',\n",
       " 'Schofield, Alexandra  and',\n",
       " 'Alex, Beatrice  and',\n",
       " 'Vajjala, Sowmya',\n",
       " 'Pannitto, Ludovica  and',\n",
       " 'Chaudhary, Aditi  and',\n",
       " 'Pham, MinhQuang  and',\n",
       " 'Gritta, Milan  and',\n",
       " 'Roy, Aurko  and',\n",
       " 'Luo, Jiaming  and',\n",
       " 'Fan, Angela  and',\n",
       " 'Pacheco, Maria Leonor  and',\n",
       " 'Mohammadshahi, Alireza  and',\n",
       " 'Williams, Adina  and',\n",
       " 'Elazar, Yanai  and',\n",
       " 'Wang, Xiaozhi  and',\n",
       " 'Bogin, Ben  and',\n",
       " 'Hayashi, Hiroaki  and',\n",
       " 'Wu, Zhaofeng  and',\n",
       " 'Prange, Jakob  and',\n",
       " 'Park, Hyunji Hayley  and',\n",
       " 'Angelidis, Stefanos  and',\n",
       " 'Jacovi, Alon  and',\n",
       " 'Xu, Weijia  and',\n",
       " 'Luan, Yi  and',\n",
       " 'Geva, Mor  and',\n",
       " 'Yogatama, Dani  and',\n",
       " 'Raghu, Dinesh  and',\n",
       " 'Fabbri, Alexander R.  and',\n",
       " 'Ponti, Edoardo M.  and',\n",
       " 'Shimorina, Anastasia  and',\n",
       " 'Choi, Eunsol  and',\n",
       " 'Sun, Zhewei  and',\n",
       " 'Lyu, Lijun  and',\n",
       " 'Culkin, Ryan  and',\n",
       " 'Puduppully, Ratish  and',\n",
       " 'Lamont, Andrew',\n",
       " 'Lucy, Li  and',\n",
       " 'Liao, Lizi  and',\n",
       " 'Hendricks, Lisa Anne  and',\n",
       " 'Ghaddar, Abbas  and',\n",
       " 'Wang, Jianyou  and',\n",
       " 'Shen, Aili  and',\n",
       " 'Zhou, Meng  and',\n",
       " 'Liu, Qi  and',\n",
       " 'Zmigrod, Ran  and',\n",
       " 'Sabo, Ofer  and',\n",
       " 'Schiffer, Lena Katharina  and',\n",
       " 'Jo, Yohan  and',\n",
       " '{Tang, Gongbo  and',\n",
       " 'Stengel-Eskin, Elias  and',\n",
       " 'Deutsch, Daniel  and',\n",
       " 'Lamm, Matthew  and',\n",
       " 'Peng, Baolin  and',\n",
       " \"Gar{\\\\'\\\\i} Soler, Aina  and\",\n",
       " 'Savoldi, Beatrice  and',\n",
       " 'Buch, Shyamal  and',\n",
       " 'Hahn, Michael  and',\n",
       " 'Bareket, Dan  and',\n",
       " 'Khattab, Omar  and',\n",
       " 'Isonuma, Masaru  and',\n",
       " 'Jiang, Zhengbao  and',\n",
       " 'Bugliarello, Emanuele  and',\n",
       " 'Udagawa, Takuma  and',\n",
       " '{Elazar, Yanai  and',\n",
       " 'Mou, Xiangyang  and',\n",
       " 'Merrill, William  and',\n",
       " 'Ganesh, Prakhar  and',\n",
       " 'Jiang, Nanjiang  and',\n",
       " '{Lewis, Patrick  and',\n",
       " 'Adelani, David Ifeoluwa  and',\n",
       " 'Deutsch, Daniel  and',\n",
       " 'Khashabi, Daniel  and',\n",
       " '{\\\\.Z}elasko, Piotr  and',\n",
       " 'Begu{\\\\v{s}}, Ga{\\\\v{s}}per',\n",
       " 'Jain, Parag  and',\n",
       " 'Chan, Hou Pong  and',\n",
       " '{Bisazza, Arianna  and',\n",
       " 'Czarnowska, Paula  and',\n",
       " 'Huang, Jiayuan  and',\n",
       " 'Rijhwani, Shruti  and',\n",
       " 'Kojima, Noriyuki  and',\n",
       " 'Effland, Thomas  and',\n",
       " 'Lakhotia, Kushal  and',\n",
       " 'Rotman, Guy  and',\n",
       " 'Mitropolsky, Daniel  and',\n",
       " 'Longpre, Shayne  and',\n",
       " '{Elazar, Yanai  and',\n",
       " '{Schick, Timo  and',\n",
       " 'Opitz, Juri  and',\n",
       " 'Li, Jiaoda  and',\n",
       " 'Freitag, Markus  and',\n",
       " 'Narayan, Shashi  and',\n",
       " 'Ouchi, Hiroki  and',\n",
       " 'Lertvittayakumjorn, Piyawat  and',\n",
       " 'Francis, David  and',\n",
       " 'Zeng, Ziheng  and',\n",
       " 'Pezzelle, Sandro  and',\n",
       " 'Moosavi, Nafise Sadat  and',\n",
       " '',\n",
       " 'Zhou, Zachary  and',\n",
       " 'Bannour, Nesrine  and',\n",
       " 'Soltan, Saleh  and',\n",
       " 'Jeon, Sungho  and',\n",
       " 'Gupta, Ankit  and',\n",
       " 'Liu, Yi  and',\n",
       " 'Sidiropoulos, Georgios  and',\n",
       " 'Zhang, Yue  and',\n",
       " 'Glenski, Maria  and',\n",
       " 'Wang, Gengyu  and',\n",
       " 'Torbarina, Lovre  and',\n",
       " 'Puvis de Chavannes, Lucas H{\\\\o}yberg  and',\n",
       " 'He, Haoyu  and',\n",
       " 'Peng, Zilun  and',\n",
       " 'Agrawal, Ameeta  and',\n",
       " 'Sachidananda, Vin  and',\n",
       " 'Gupta, Ankur  and',\n",
       " 'Ku, Lun-Wei  and',\n",
       " '',\n",
       " 'Pedinotti, Paolo  and',\n",
       " 'Laverghetta Jr., Antonio  and',\n",
       " 'Noble, Bill  and',\n",
       " 'Jannatus Saba, Syeda  and',\n",
       " 'MacLaughlin, Ansel  and',\n",
       " 'Paul, Debjit  and',\n",
       " 'Chen, Zeming  and',\n",
       " 'Rozen, Ohad  and',\n",
       " 'Zarharan, Majid  and',\n",
       " 'Grimm, Frank  and',\n",
       " 'Indurkhya, Sagar  and',\n",
       " 'Ou, Jiefu  and',\n",
       " 'Cattan, Arie  and',\n",
       " 'Pappadopulo, Duccio  and',\n",
       " 'Kwon, Heeyoung  and',\n",
       " 'Damonte, Marco  and',\n",
       " 'Xia, Menglin  and',\n",
       " 'Zhai, Fangzhou  and',\n",
       " 'Shou, Ziyi  and',\n",
       " 'Yamamoto, Yuki  and',\n",
       " 'Kehat, Gitit  and',\n",
       " 'Zhao, Wei  and',\n",
       " 'Schlechtweg, Dominik  and',\n",
       " '{H{\\\\\"a}tty, Anna  and',\n",
       " 'Thorn Jakobsen, Terne Sasha  and',\n",
       " 'Li, Xiaotao  and',\n",
       " 'Malon, Christopher',\n",
       " 'Caciularu, Avi  and',\n",
       " 'Hakimi Parizi, Ali  and',\n",
       " 'Yang, Ziqing  and',\n",
       " 'Kozareva, Zornitsa  and',\n",
       " '',\n",
       " 'Parnell, Jacob  and',\n",
       " 'Rubin, Ohad  and',\n",
       " 'Groschwitz, Jonas  and',\n",
       " 'Kreutzer, Julia  and',\n",
       " 'Kulikov, Ilia  and',\n",
       " 'Dayanik, Erenay  and',\n",
       " '{Huang, Chenyang  and',\n",
       " 'Zhang, Zhisong  and',\n",
       " 'Alikhani, Malihe  and',\n",
       " '',\n",
       " 'Appelgren, Mattias  and',\n",
       " 'Katsakioris, Miltiadis Marios  and',\n",
       " 'Dong, Tianai  and',\n",
       " 'Platonov, Georgiy  and',\n",
       " 'Zhang, Yue  and',\n",
       " 'Staniek, Michael  and',\n",
       " 'Korpan, Raj  and',\n",
       " 'Jeon, Haein  and',\n",
       " 'Kulkarni, Sayali  and',\n",
       " 'Ku, Lun-Wei  and',\n",
       " '',\n",
       " 'Roy, Shamik  and',\n",
       " 'Di Giovanni, Marco  and',\n",
       " 'Kobayashi, Hayato  and',\n",
       " 'Cao, Ivy  and',\n",
       " 'Zhou, Karen  and',\n",
       " 'Glenski, Maria  and',\n",
       " 'Larimore, Savannah  and',\n",
       " 'Mosca, Edoardo  and',\n",
       " \"Jarqu{\\\\'\\\\i}n-V{\\\\'a}squez, Horacio  and\",\n",
       " 'Bose, Tulika  and',\n",
       " 'Wood-Doughty, Zach  and',\n",
       " \"Gjurkovi{\\\\'c}, Matej  and\",\n",
       " 'Dong, MeiXing  and',\n",
       " 'Chen, Shuguang  and',\n",
       " 'Oh, Soyoung  and',\n",
       " 'Tian, Yufei  and',\n",
       " 'Magge, Arjun  and',\n",
       " '',\n",
       " 'Niu, Jingcheng  and',\n",
       " 'Karisani, Payam  and',\n",
       " '{Miranda-Escalada, Antonio  and',\n",
       " 'Magge, Arjun  and',\n",
       " 'Ramesh, Sidharth  and',\n",
       " 'Sakhovskiy, Andrey  and',\n",
       " 'Dima, George-Andrei  and',\n",
       " 'Guo, Yuting  and',\n",
       " 'Aji, Alham Fikri  and',\n",
       " 'Valdes, Alberto  and',\n",
       " 'Carreto Fidalgo, David  and',\n",
       " \"Santamar{\\\\'\\\\i}a Carrasco, Sergio  and\",\n",
       " 'Zhou, Tong  and',\n",
       " 'Yaseen, Usama  and',\n",
       " 'Kayastha, Tanay  and',\n",
       " 'Elkaref, Mohab  and',\n",
       " 'Blinov, Pavel',\n",
       " 'Lee, Lung-Hao  and',\n",
       " 'Kumar, Deepak  and',\n",
       " \"Pach{\\\\'o}n, Victoria  and\",\n",
       " 'Ruas, Pedro  and',\n",
       " 'Kumar, Adarsh  and',\n",
       " 'Laureano De Leon, Frances Adriana  and',\n",
       " 'Pimpalkhute, Varad  and',\n",
       " 'Luo, Ying  and',\n",
       " 'Ji, Zongcheng  and',\n",
       " 'Pais, Vasile  and',\n",
       " 'Fleming, Max  and',\n",
       " 'Mondal, Anupam  and',\n",
       " 'Roychoudhury, Rajarshi  and',\n",
       " 'Mesa Murgado, Alberto  and',\n",
       " 'Cornelius, Joseph  and',\n",
       " 'Ojha, Atul Kr.  and',\n",
       " '{Vylomova, Ekaterina  and',\n",
       " '',\n",
       " 'Marjou, Xavier',\n",
       " 'Inglese, Guglielmo  and',\n",
       " 'Iwamoto, Ran  and',\n",
       " 'Kandula, Hemanth  and',\n",
       " 'Choudhary, Chinmay',\n",
       " 'Ellsworth, Michael  and',\n",
       " 'Zhou, Zhong  and',\n",
       " '{Hammarstr{\\\\\"o}m, Harald},',\n",
       " 'Sahai, Saumya  and',\n",
       " 'Mikhailov, Vladislav  and',\n",
       " 'Salesky, Elizabeth  and',\n",
       " 'Bedyakin, Roman  and',\n",
       " 'Celano, Giuseppe G. A.',\n",
       " 'Scherbakov, Andreas  and',\n",
       " 'Nicolai, Garrett  and',\n",
       " '',\n",
       " 'Roewer-Despres, Francois  and',\n",
       " 'Dolatian, Hossep  and',\n",
       " 'Papillon, Maxime',\n",
       " 'Kirby, James',\n",
       " 'Batsuren, Khuyagbaatar  and',\n",
       " 'Jayanthi, Sai Muralidhar  and',\n",
       " 'Vaduguru, Saujas  and',\n",
       " 'Wiemerslage, Adam  and',\n",
       " 'McCurdy, Kate  and',\n",
       " 'Perkoff, E. Margaret  and',\n",
       " 'Yang, Changbing  and',\n",
       " 'Gerlach, Andrew  and',\n",
       " 'Ashby, Lucas F.E.  and',\n",
       " 'Hammond, Michael',\n",
       " 'Lo, Roger Yu-Hsiang  and',\n",
       " 'Gautam, Vasundhara  and',\n",
       " 'Clematide, Simon  and',\n",
       " 'Elsner, Micha',\n",
       " 'Dai, Huteng  and',\n",
       " 'Wang, Yang',\n",
       " 'Forbes, Clarissa  and',\n",
       " 'Ryskina, Maria  and',\n",
       " 'Markowska, Magdalena  and',\n",
       " 'Sharma, Dravyansh  and',\n",
       " 'Pimentel, Tiago  and',\n",
       " 'Ek, Adam  and',\n",
       " \"Szolnok, G{\\\\'a}bor  and\",\n",
       " 'Calderone, Basilio  and',\n",
       " 'Wilson, Colin  and',\n",
       " 'Li, Haizhou  and',\n",
       " '',\n",
       " 'See, Abigail  and',\n",
       " 'Ward, Nigel  and',\n",
       " 'Kottur, Satwik  and',\n",
       " 'Ward, Nigel',\n",
       " 'Liang, Kai-Hui  and',\n",
       " 'Nguyen, Minh  and',\n",
       " 'Ravi, Sujith  and',\n",
       " 'Heidari, Peyman  and',\n",
       " 'Tanaka, Shohei  and',\n",
       " 'Higashinaka, Ryuichiro  and',\n",
       " 'Hardy, Amelia  and',\n",
       " 'Papangelis, Alexandros  and',\n",
       " 'Zhou, Pei  and',\n",
       " 'Aksu, Ibrahim Taha  and',\n",
       " 'Kottur, Satwik  and',\n",
       " 'Shen, Aili  and',\n",
       " 'Konigari, Rachna  and',\n",
       " 'Xing, Linzi  and',\n",
       " 'Miyazaki, Chiaki  and',\n",
       " 'Zhao, Tianyu  and',\n",
       " 'Okano, Koshiro  and',\n",
       " 'Tian, Ye  and',\n",
       " 'Dey, Suvodip  and',\n",
       " 'Zhou, Jingyao  and',\n",
       " 'Balaraman, Vevake  and',\n",
       " 'Liesenfeld, Andreas  and',\n",
       " 'Ishii, Etsuko  and',\n",
       " 'Inoue, Koji  and',\n",
       " 'Chierici, Alberto  and',\n",
       " 'Si, Wai Man  and',\n",
       " 'Gupta, Itika  and',\n",
       " 'Nasreen, Shamila  and',\n",
       " 'Ghosal, Deepanway  and',\n",
       " 'Atwell, Katherine  and',\n",
       " 'Qian, Kun  and',\n",
       " 'Mahajan, Khyati  and',\n",
       " 'Gervits, Felix  and',\n",
       " 'Brenneis, Markus  and',\n",
       " 'Rach, Niklas  and',\n",
       " 'Alhindi, Tariq  and',\n",
       " '{Do{\\\\u{g}}ru{\\\\\"o}z, A. Seza  and',\n",
       " 'Ultes, Stefan  and',\n",
       " '{Sch{\\\\\"u}z, Simeon  and',\n",
       " 'Assem, Haytham  and',\n",
       " 'Ekstedt, Erik  and',\n",
       " 'Romero, Oscar J.  and',\n",
       " 'Lin, Hsien-chin  and',\n",
       " 'Liao, Ling-Yen  and',\n",
       " 'Parthasarathi, Prasanna  and',\n",
       " 'Parthasarathi, Prasanna  and',\n",
       " 'Mehri, Shikib  and',\n",
       " 'Mehri, Shikib  and',\n",
       " 'Liu, Zhengyuan  and',\n",
       " 'Zhuang, Yingying  and',\n",
       " 'Manuvinakurike, Ramesh  and',\n",
       " 'Karan, Mladen  and',\n",
       " 'Bang, Yejin  and',\n",
       " 'Li, Haojun  and',\n",
       " 'Lewis, Martha  and',\n",
       " '',\n",
       " 'Aguirre-Celis, Nora  and',\n",
       " 'Rizzo, Irene',\n",
       " 'Yeung, Richie  and',\n",
       " 'Coecke, Bob  and',\n",
       " 'Wang, Daphne  and',\n",
       " 'Rodatz, Benjamin  and',\n",
       " 'Duneau, Tiffany',\n",
       " 'Widdows, Dominic  and',\n",
       " 'Palmer, Alexis  and',\n",
       " '',\n",
       " 'Shardlow, Matthew  and',\n",
       " 'Taya, Yuki  and',\n",
       " 'Martelli, Federico  and',\n",
       " 'Zheng, Boyuan  and',\n",
       " 'Zhang, Jing  and',\n",
       " 'Pavlopoulos, John  and',\n",
       " 'Dimitrov, Dimitar  and',\n",
       " 'Feng, Zhida  and',\n",
       " 'Meaney, J. A.  and',\n",
       " 'Agarwal, Raksha  and',\n",
       " 'Ortiz-Zambrano, Jenny A.  and',\n",
       " 'Gombert, Sebastian  and',\n",
       " 'Liebeskind, Chaya  and',\n",
       " 'Rivas Rojas, Kervy  and',\n",
       " 'You, Huiling  and',\n",
       " 'Razzhigaev, Anton  and',\n",
       " 'Zhestiankin, Boris  and',\n",
       " \"Berend, G{\\\\'a}bor\",\n",
       " 'Mittal, Abhishek  and',\n",
       " 'Liu, Pingsheng  and',\n",
       " 'Sharma, Abheesht  and',\n",
       " 'Xie, Yuqiang  and',\n",
       " 'Basafa, Hossein  and',\n",
       " 'Bansal, Archit  and',\n",
       " 'Karimi, Akbar  and',\n",
       " 'Paraschiv, Andrei  and',\n",
       " 'Chhablani, Gunjan  and',\n",
       " 'Yan, Erik  and',\n",
       " 'Ghosh, Sreyan  and',\n",
       " 'Wang, Zhen  and',\n",
       " 'Ding, Huiyang  and',\n",
       " 'Roele, Cees',\n",
       " 'Xie, Yubo  and',\n",
       " 'Liu, Renyuan  and',\n",
       " 'Pang, Chao  and',\n",
       " 'Gupta, Aishwarya  and',\n",
       " 'Labadie, Roberto  and',\n",
       " 'Harper, Corey  and',\n",
       " 'Wang, Nancy X. R.  and',\n",
       " 'Jindal, Aditya  and',\n",
       " 'Uma, Alexandra  and',\n",
       " '{Laparra, Egoitz  and',\n",
       " 'Wang, Weikang  and',\n",
       " \"{D{'}Souza, Jennifer  and\",\n",
       " 'Liu, Haoyang  and',\n",
       " 'Karia, Neel  and',\n",
       " 'Pouran Ben Veyseh, Amir  and',\n",
       " 'Lathiff, Nihatha  and',\n",
       " 'Therien, Benjamin  and',\n",
       " 'Zhou, Yuxuan  and',\n",
       " '{M{\\\\\"u}ller, Thomas  and',\n",
       " '{K{\\\\\"o}ksal, Abdullatif  and',\n",
       " 'Kumar, Harshit  and',\n",
       " 'Kurniawan, Kemal  and',\n",
       " 'Yoon, Sangwon  and',\n",
       " 'Su, Xin  and',\n",
       " 'Shailabh, Shashank  and',\n",
       " 'Ma, Xinge  and',\n",
       " 'Zhang, Genyu  and',\n",
       " 'Martin, Anna  and',\n",
       " 'Arora, Hardik  and',\n",
       " 'Gupta, Rohan  and',\n",
       " 'Zhu, Qinglin  and',\n",
       " 'Faraj, Dalya  and',\n",
       " 'Avram, Andrei-Marius  and',\n",
       " 'Shirude, Neil  and',\n",
       " 'Desai, Abhinandan Tejalkumar  and',\n",
       " 'Mosquera, Alejandro',\n",
       " 'Vettigli, Giuseppe  and',\n",
       " 'Xiang, Rong  and',\n",
       " 'Bestgen, Yves',\n",
       " 'Pan, Chunguang  and',\n",
       " 'El Mamoun, Nabil  and',\n",
       " 'Yuan, Zheng  and',\n",
       " 'Huang, Bo  and',\n",
       " 'Flynn, Robert  and',\n",
       " 'Zaharia, George-Eduard  and',\n",
       " 'Paetzold, Gustavo Henrique',\n",
       " 'Rao, Gang  and',\n",
       " 'Aziz, Abdul  and',\n",
       " '{Smolenska, Greta  and',\n",
       " 'Stodden, Regina  and',\n",
       " 'King, Milton  and',\n",
       " 'Rotaru, Armand',\n",
       " 'Bani Yaseen, Tuqa  and',\n",
       " 'Islam, Aadil  and',\n",
       " 'Nandy, Abhilash  and',\n",
       " 'Almeida, Raul  and',\n",
       " 'Rozi, Erik  and',\n",
       " 'Russo, Irene',\n",
       " 'Voskoboinik, Katja',\n",
       " 'Xie, Wanying',\n",
       " 'Xie, Shuyi  and',\n",
       " 'Huang, Bo  and',\n",
       " 'Ranjbar, Niloofar  and',\n",
       " 'Yuan, Zheng  and',\n",
       " 'Li, Wei  and',\n",
       " 'Goyal, Harsh  and',\n",
       " 'Al-Hajj, Moustafa  and',\n",
       " 'Rachinskiy, Maxim  and',\n",
       " 'Hauer, Bradley  and',\n",
       " 'Hettiarachchi, Hansi  and',\n",
       " 'Davletov, Adis  and',\n",
       " 'Bodnar, Ciprian  and',\n",
       " 'Jiang, Yuxin  and',\n",
       " 'Markchom, Thanet  and',\n",
       " 'Shukla, Shikhar  and',\n",
       " 'Xie, Xin  and',\n",
       " 'Wang, Ye  and',\n",
       " 'Chen, Zhixiang  and',\n",
       " 'Ranasinghe, Tharindu  and',\n",
       " 'Chen, Ruijun  and',\n",
       " 'Luu, Son T.  and',\n",
       " \"Pluci{\\\\'n}ski, Kamil  and\",\n",
       " 'Palomino, Marco  and',\n",
       " 'Benlahbib, Abdessamad  and',\n",
       " 'Wang, Chenyi  and',\n",
       " 'Suman, Thakur Ashutosh  and',\n",
       " 'Rusert, Jonathan',\n",
       " 'Nguyen, Viet Anh  and',\n",
       " 'Burtenshaw, Ben  and',\n",
       " 'Huang, Bo  and',\n",
       " '{Delil, Selman  and',\n",
       " 'Kotyushev, Mikhail  and',\n",
       " 'Gia Hoang, Phu  and',\n",
       " 'Dale, David  and',\n",
       " 'Jain, Vaibhav  and',\n",
       " 'Kataria, Harsh  and',\n",
       " 'Babaei Giglou, Hamed  and',\n",
       " 'Sharma, Mayukh  and',\n",
       " 'Palliser-Sans, Rafel  and',\n",
       " 'Khan, Yakoob  and',\n",
       " 'Sat{\\\\l}awa, Micha{\\\\l}  and',\n",
       " 'Plaza-del-Arco, Flor Miriam  and',\n",
       " 'Hossain, Tashin  and',\n",
       " 'Salemi, Alireza  and',\n",
       " 'Cech, Maggie',\n",
       " 'Zou, Liang  and',\n",
       " 'Ghadery, Erfan  and',\n",
       " 'Messina, Nicola  and',\n",
       " \"Kaczy{\\\\'n}ski, Konrad  and\",\n",
       " 'Li, Peiguang  and',\n",
       " 'Pritzkau, Albert',\n",
       " 'Zhu, Xingyu  and',\n",
       " 'Singh, Pranaydeep  and',\n",
       " 'Hou, Xiaolong  and',\n",
       " 'Gupta, Vansh  and',\n",
       " 'Abujaber, Dia  and',\n",
       " 'Gupta, Kshitij  and',\n",
       " 'Tian, Junfeng  and',\n",
       " 'Hossain, Tashin  and',\n",
       " \"Garc{\\\\'\\\\i}a-D{\\\\'\\\\i}az, Jos{\\\\'e} Antonio  and\",\n",
       " 'Al Bashabsheh, Emran  and',\n",
       " 'Guan, Zhengyi  and',\n",
       " 'Al-Omari, Hani  and',\n",
       " 'Yang, Maoqin',\n",
       " 'Karasakalidis, Alexandros  and',\n",
       " 'Song, Bingyan  and',\n",
       " 'Essefar, Kabil  and',\n",
       " 'Huang, Bo  and',\n",
       " 'Sharma, Mayukh  and',\n",
       " 'Ma, Jian  and',\n",
       " 'Sm{\\\\u{a}}du, R{\\\\u{a}}zvan-Alexandru  and',\n",
       " 'Mondal, Anik  and',\n",
       " 'Zhao, Yingjia  and',\n",
       " 'Liu, Zehao  and',\n",
       " 'Sivanaiah, Rajalakshmi  and',\n",
       " 'Zylich, Brian  and',\n",
       " 'Akrah, Samuel',\n",
       " 'Sultana, Afrin  and',\n",
       " 'Chi, Nathan  and',\n",
       " 'Pandey, Chandan Kumar  and',\n",
       " 'Raha, Tathagata  and',\n",
       " 'Samson, Mihai  and',\n",
       " 'Gangwar, Akash  and',\n",
       " 'Cao, Jiarun  and',\n",
       " 'Liu, Patrick  and',\n",
       " 'Davletov, Adis  and',\n",
       " 'Ruan, Xiaoyi  and',\n",
       " 'Gautam, Devansh  and',\n",
       " 'Acharya, Kaushik',\n",
       " 'Varma, Harshit  and',\n",
       " 'Sun, Jinquan  and',\n",
       " 'Yu, Zhewen  and',\n",
       " ...]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a461a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, 70092 rows of authors were remaining.\n"
     ]
    }
   ],
   "source": [
    "# Some cleaning\n",
    "\n",
    "minletters = 5 \n",
    "authors_clean = []\n",
    "\n",
    "for a in authors: \n",
    "    if len(a) > minletters and len(re.findall('[a-zA-Z]',a)) >0.6*len(a):\n",
    "        authors_clean.append(a) \n",
    "print(\"After cleaning, {} rows of authors were remaining.\".format(len(authors_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10c2b0",
   "metadata": {},
   "source": [
    "### Report the essential description of data.\n",
    "-\tDon’t print out dozens of raw lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7960491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>5.304838</td>\n",
       "      <td>15.411135</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_count</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>29.245668</td>\n",
       "      <td>103.730310</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>5.632325</td>\n",
       "      <td>1.527317</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>1.361732</td>\n",
       "      <td>5.583222</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>0.081769</td>\n",
       "      <td>0.426801</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean         std   min        25%        50%  \\\n",
       "word_count  72081.0   5.304838   15.411135  1.00   4.000000   4.000000   \n",
       "char_count  72081.0  29.245668  103.730310  6.00  16.000000  19.000000   \n",
       "avg_word    72081.0   5.632325    1.527317  2.25   4.666667   5.333333   \n",
       "stopwords   72081.0   1.361732    5.583222  0.00   1.000000   1.000000   \n",
       "upper       72081.0   0.081769    0.426801  0.00   0.000000   0.000000   \n",
       "\n",
       "                  75%     max  \n",
       "word_count   4.000000   414.0  \n",
       "char_count  22.000000  2673.0  \n",
       "avg_word     6.333333    43.0  \n",
       "stopwords    1.000000   158.0  \n",
       "upper        0.000000    34.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(authors_clean, columns=['authors'])\n",
    "# Number of words\n",
    "data['word_count'] = data['authors'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['authors','word_count']]\n",
    "\n",
    "#Number of characters\n",
    "data['char_count'] = data['authors'].str.len() ## this also includes spaces\n",
    "data[['authors','char_count']]\n",
    "\n",
    "# Average word length\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['authors'].apply(lambda x: avg_word(x))\n",
    "\n",
    "# Number of stop words \n",
    "stop = stopwords.words('english')\n",
    "data['stopwords'] = data['authors'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "# Number of Uppercase words\n",
    "data['upper'] = data['authors'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "# Descriptive statistics of the DataFrame\n",
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ec9d0",
   "metadata": {},
   "source": [
    "## 3.\tModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31d661",
   "metadata": {},
   "source": [
    "### Prepare analytics here and construct all the data objects you will use in your report.\n",
    "•\tWrite functions and classes to simplify tasks. Do not repeat yourself.\n",
    "\n",
    "•\tAvoid output.\n",
    "\n",
    "•\tRefactor your code until it’s clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7478ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdata(k, fname=\"data/data.txt\", report=False):\n",
    "    C_k = []\n",
    "    b = 0\n",
    "\n",
    "    for line in fname:\n",
    "        line = line.replace('\\n', '')  # remove newline symbol\n",
    "        if report:\n",
    "            print(line)\n",
    "         \n",
    "        if line != \"\":\n",
    "            # gather all items in one basket\n",
    "            C_k.append(line)\n",
    "        else:\n",
    "            # end of basket, report all itemsets\n",
    "            for itemset in itertools.combinations(C_k, k):\n",
    "                yield frozenset(itemset)\n",
    "            C_k = []\n",
    "                \n",
    "            if report:\n",
    "                print(\"\")\n",
    "\n",
    "            # report progress\n",
    "            # print every 1000th element to reduce clutter\n",
    "            if report:\n",
    "                if b % 1000 == 0:\n",
    "                    print('processing bin ', b)\n",
    "                b += 1\n",
    "\n",
    "    # last basket\n",
    "    if len(C_k) > 0:\n",
    "        for itemset in itertools.combinations(C_k, k):\n",
    "            yield frozenset(itemset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9906646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33590 items\n",
      "3328 items with >5 occurances\n"
     ]
    }
   ],
   "source": [
    "N = 5  # frequency threshold\n",
    "\n",
    "\n",
    "# find frequent 1-tuples (individual items)\n",
    "C1 = {}\n",
    "for key in readdata(k=1, fname=data[\"authors\"], report=False):\n",
    "    if key not in C1:\n",
    "        C1[key] = 1\n",
    "    else:\n",
    "        C1[key] += 1    \n",
    "        \n",
    "print(\"{} items\".format(len(C1)))\n",
    "\n",
    "# filter stage\n",
    "L1 = {}\n",
    "for key, count in C1.items():\n",
    "    if count >= N:\n",
    "        L1[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L1), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "253c5aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0s for k=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({'a', 'd'}): 8,\n",
       " frozenset({'d', 't'}): 8,\n",
       " frozenset({'/', 'd'}): 2,\n",
       " frozenset({'d'}): 1,\n",
       " frozenset({'.', 'd'}): 2,\n",
       " frozenset({'d', 'x'}): 2,\n",
       " frozenset({'a', 't'}): 16,\n",
       " frozenset({'a'}): 6,\n",
       " frozenset({'/', 'a'}): 4,\n",
       " frozenset({'.', 'a'}): 4,\n",
       " frozenset({'a', 'x'}): 4,\n",
       " frozenset({'/', 't'}): 4,\n",
       " frozenset({'t'}): 6,\n",
       " frozenset({'.', 't'}): 4,\n",
       " frozenset({'t', 'x'}): 4,\n",
       " frozenset({'.', '/'}): 1,\n",
       " frozenset({'/', 'x'}): 1,\n",
       " frozenset({'.', 'x'}): 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_C(k):\n",
    "\n",
    "    start = time.time()\n",
    "    C = {}\n",
    "    for key in readdata(k):  # False report\n",
    "        if key not in C:\n",
    "            C[key] = 1\n",
    "        else:\n",
    "            C[key] += 1\n",
    "    print(\"Took {}s for k={}\".format((time.time() - start), k))\n",
    "    return C\n",
    "\n",
    "get_C(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69b9f81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', \"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\")\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', \"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\")\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.', 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "('Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for c in itertools.combinations(data[\"abstracts\"][1:8], 2):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42f74cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.combinations at 0x1cab0dc1450>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itertools.combinations(data[\"abstracts\"][1:8],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f720ea6",
   "metadata": {},
   "source": [
    "## 4.\tResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da595a1c",
   "metadata": {},
   "source": [
    "•\tPrint out relevant tables nicely, display well-annotated charts and explain if needed in plain English.\n",
    "•\tUse minimum code here, just output-functions’ calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b7367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9665180",
   "metadata": {},
   "source": [
    "## 5.\tConclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61341687",
   "metadata": {},
   "source": [
    "•\tSummarize your findings here in 5...10 lines of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bff0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7841c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'Project' did not match any files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 8db0450] added Project 2\n",
      " 3 files changed, 407 insertions(+), 36 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in .ipynb_checkpoints/Project 2-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in Project 1.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in Project 2.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "To https://github.com/AlexTouvras/FindingSimilarItems\n",
      "   9c4ee28..8db0450  main -> main\n"
     ]
    }
   ],
   "source": [
    "# ! git add Project 2\n",
    "# ! git commit -am \"added Project 2\" \n",
    "# ! git push "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
