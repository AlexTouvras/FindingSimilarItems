{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee5ea2e",
   "metadata": {},
   "source": [
    "# Finding Similar Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec96974",
   "metadata": {},
   "source": [
    "## 1.\tIntroduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec837ab",
   "metadata": {},
   "source": [
    "### Frequent pairs of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e85903",
   "metadata": {},
   "source": [
    "- Extract a list of the authors or editors per publication from the ACL Anthology dataset (https://aclanthology.org/) and create baskets and perform a search on the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577232b9",
   "metadata": {},
   "source": [
    "1. Find the frequent pair of items (2-tuples) using the naïve, A-priori and PCY algorithms. For each of these compare the time of execution and results for supports s=10, 50, 100. Comment your results. \n",
    "\n",
    "2. For the PCY algorithm, create up to 5 compact hash tables. What is  the difference in results and time of execution for 1,2,3,4 and 5 tables? Comment your results.\n",
    "\n",
    "3. Find the final list of k-frequent items (k-tuples) for k=3 and 4. Experiment a bit and describe the best value for the support in each case. *Warning*: You can use any of the three algorithms, but be careful, because the algorithm can take too long if you don't chose it properly (well, basically don't use the naïve approach ;)).\n",
    "\n",
    "4. Using one of the results of the previous items, for one k (k=2 or 3) find the possible clusters using the 1-NN criteria. Comment your results.\n",
    "\n",
    "> 1-NN means that if you have a tuple {A,B,C} and {C,E,F} then because they share one element {C}, then they belong to the same cluster  {A,B,C,E,F}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10f72c",
   "metadata": {},
   "source": [
    "-\tDefine all and only used package imports below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc996b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alext\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests # to download the dataset\n",
    "import gzip\n",
    "import shutil # to extract the gz file\n",
    "import re # for text cleaning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from nltk.corpus import stopwords # calculation of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50648126",
   "metadata": {},
   "source": [
    "## 2.\tELT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41c6c9",
   "metadata": {},
   "source": [
    "### Extract, Load and Transform of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacac31b",
   "metadata": {},
   "source": [
    "- In your code data should be retrieved from an online source, NOT from your local drive, otherwise, nobody can run your code without additional effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7340d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data \n",
    "url = 'https://aclanthology.org/anthology+abstracts.bib.gz'\n",
    "filename = url.split(\"/\")[-1]\n",
    "with open(filename, \"wb\") as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)\n",
    "\n",
    "# Extract the gz file\n",
    "with gzip.open('anthology+abstracts.bib.gz', 'rb') as f_in:\n",
    "    with open('anthology+abstracts.bib', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe150b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows of authors were found in the file.\n"
     ]
    }
   ],
   "source": [
    "# Find all the rows in the file that contain an abstract and laod the text to a list\n",
    "authors = []\n",
    "with open(\"anthology+abstracts.bib\", \"r\",encoding=\"UTF-8\") as f:\n",
    "    \n",
    "    for line in f:\n",
    "        if \"author =\" in line or \"editor =\" in line:\n",
    "            break\n",
    "                \n",
    "        # get abstract as a single string\n",
    "        author = ' '.join([line[:-1].strip() for line in f])\n",
    "        author = re.sub(' +', ' ', author)  # remove double spaces\n",
    "        \n",
    "   \n",
    "    f.close()\n",
    "    f.close()\n",
    "\n",
    "print(\"{} rows of authors were found in the file.\".format(len(authors)))\n",
    "#the issue here is that only the first row after author/editor is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfa52809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73129 rows of authors were found in the file.\n"
     ]
    }
   ],
   "source": [
    "# Find all the rows in the file that contain an abstract and laod the text to a list\n",
    "authors = []\n",
    "with open(\"anthology+abstracts.bib\", \"r\",encoding=\"UTF-8\") as f:\n",
    "    s = f.readlines()\n",
    "    for x in s:\n",
    "        if x.__contains__('author ='):\n",
    "            start = x.find('    author = \"') + len('    author = \"')\n",
    "            end = x.find('  and')\n",
    "            substring = x[start:end].replace(',', '')\n",
    "            authors.append(substring)\n",
    "        if x.__contains__('editor ='):\n",
    "            start = x.find('    editor = \"') + len('    editor = \"')\n",
    "            end = x.find('  and')\n",
    "            substring = x[start:end].replace(',', '')\n",
    "            authors.append(substring)\n",
    "\n",
    "    f.close()\n",
    "    f.close()\n",
    "\n",
    "print(\"{} rows of authors were found in the file.\".format(len(authors)))\n",
    "#the issue here is that only the first row after author/editor is stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85373b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mostafazadeh Davani Aida',\n",
       " 'Singh Sumer',\n",
       " 'Hahn Vanessa',\n",
       " 'Caselli Tommaso',\n",
       " 'Kirk Hannah',\n",
       " 'Kivlichan Ian',\n",
       " 'Caselli Tommaso',\n",
       " 'Niraula Nobal B.',\n",
       " 'Fortuna Paula',\n",
       " 'Manerba Marta Marchiori',\n",
       " 'Mostafazadeh Davani Aida',\n",
       " 'Zad Samira',\n",
       " 'Chuang Yung-Sung',\n",
       " 'Aksenov Dmitrii',\n",
       " 'Sodhi Ravsimar',\n",
       " 'Xenos Alexandros',\n",
       " 'Salawu Semiu',\n",
       " 'Risch Julian',\n",
       " 'Trujillo Milo',\n",
       " 'Shvets Alexander',\n",
       " 'Bertaglia Thales',\n",
       " 'Mathias Lambert',\n",
       " 'Aggarwal Piush',\n",
       " 'Zia Haris Bin',\n",
       " 'Kougia Vasiliki',\n",
       " 'Xu Wei',\n",
       " 'Dadu Tanvi',\n",
       " 'Olsen Benjamin',\n",
       " '{H{\\\\\"a}m{\\\\\"a}l{\\\\\"a}inen Mika',\n",
       " 'Lei Yanfei',\n",
       " 'Tran Phu Minh',\n",
       " 'Le Duong',\n",
       " 'Cho Won Ik',\n",
       " 'Feucht Malte',\n",
       " 'Higashiyama Shohei',\n",
       " 'Cheong Sik Feng',\n",
       " 'Chen Shuguang',\n",
       " 'Plepi Joan',\n",
       " 'Gao Mengyi',\n",
       " 'Lent Heather',\n",
       " 'Srivastava Vivek',\n",
       " 'Aghajani MohammadMahdi',\n",
       " 'Bogensperger Johannes',\n",
       " 'Pratapa Adithya',\n",
       " 'Fu Xue-Yong',\n",
       " 'Deng Yang',\n",
       " 'Murayama Taichi',\n",
       " \"Rosales N{\\\\'u}{\\\\~n}ez Jos{\\\\'e} Carlos\",\n",
       " \"Rosales N{\\\\'u}{\\\\~n}ez Jos{\\\\'e} Carlos\",\n",
       " '{Kruspe Anna',\n",
       " 'Mirshekari Mostafa',\n",
       " 'Scaboro Simone',\n",
       " \"Jacqmin L{\\\\'e}o\",\n",
       " 'Spiliopoulou Evangelia',\n",
       " 'Shim Heereen',\n",
       " 'Li Jinfen',\n",
       " 'Soper Elizabeth',\n",
       " '{Vahtola Teemu',\n",
       " 'Bhardwaj Shivendra',\n",
       " 'Clark Thomas',\n",
       " 'Ghosh Sayan',\n",
       " 'Bertsch Amanda',\n",
       " 'Novikova Jekaterina\"',\n",
       " \"N{\\\\'a}plava Jakub\",\n",
       " 'Oliveira dos Santos Gabriel',\n",
       " 'Davidson Sam',\n",
       " 'Kashefi Omid',\n",
       " 'Mishra Shubhanshu',\n",
       " 'Lee Jian Yi David',\n",
       " 'Chinta Abhinav',\n",
       " 'Lee Sangah',\n",
       " 'Straka Milan',\n",
       " 'Riabi Arij',\n",
       " 'Priyanshu Aman',\n",
       " 'Guo Yanzhu',\n",
       " 'Ehara Yo\"',\n",
       " 'Kubal Divesh',\n",
       " 'Scherrer Yves',\n",
       " 'Bucur Ana-Maria',\n",
       " 'Samuel David',\n",
       " '{van der Goot Rob',\n",
       " 'van der Goot Rob\"',\n",
       " 'Barrault Loic',\n",
       " 'Akhbardeh Farhad',\n",
       " 'Wenzek Guillaume',\n",
       " 'Bei Chao',\n",
       " 'Chen Pinzhen',\n",
       " 'Erdmann Grant',\n",
       " 'Escolano Carlos',\n",
       " 'Gebauer Petr',\n",
       " 'Hendy Amr',\n",
       " \"S{\\\\'\\\\i}monarson Haukur Barri\",\n",
       " 'Koszowski Miko{\\\\l}aj',\n",
       " 'Le Giang',\n",
       " 'Li Zuchao',\n",
       " 'Martinez Ander\"',\n",
       " 'Nowakowski Artur',\n",
       " 'Oravecz Csaba',\n",
       " 'Pal Proyag',\n",
       " 'Qian Lihua',\n",
       " 'Subramanian Sandeep',\n",
       " 'Tran Chau',\n",
       " 'Wang Longyue',\n",
       " 'Wei Daimeng',\n",
       " 'Xu Jitao',\n",
       " 'Zeng Xianfeng',\n",
       " 'Zeng Hui\"',\n",
       " 'Zhao Shiyu',\n",
       " 'Zhou Shuhan',\n",
       " 'Adebara Ife',\n",
       " 'Canals Miguel',\n",
       " 'Laskar Sahinur Rahman',\n",
       " 'Mujadia Vandan',\n",
       " 'Rapp Reinhard\"',\n",
       " 'Saldanha Richard',\n",
       " 'Yadav Saumitra',\n",
       " 'Oh Shinhyeok',\n",
       " 'Sharma Abhishek',\n",
       " 'Guo Hangcheng',\n",
       " 'Li Zongyao',\n",
       " 'Liu Huan',\n",
       " 'Mhaskar Shivam',\n",
       " 'Park Jeonghyeok',\n",
       " 'Chen Wei-Rui',\n",
       " 'Jon Josef',\n",
       " 'Kharitonova Ksenia',\n",
       " 'Tchistiakova Svetlana',\n",
       " 'Yang Han',\n",
       " 'Bandyopadhyay Saptarashmi',\n",
       " 'Budiwati Sari Dewi',\n",
       " 'Emezue Chris Chinenye',\n",
       " 'Lai Wen',\n",
       " 'Liao Baohao',\n",
       " 'Liu Danni',\n",
       " 'Sutawika Lintang',\n",
       " 'Xie Wanying',\n",
       " 'Yang Jian',\n",
       " 'Yu Zhengzhe',\n",
       " 'Knowles Rebecca\"',\n",
       " 'Kocmi Tom',\n",
       " \"Krubi{\\\\'n}ski Mateusz\",\n",
       " 'Hanna Michael',\n",
       " 'Mirzakhalov Jamshidbek',\n",
       " 'Troles Jonas-Dario',\n",
       " 'Berard Alexandre\"',\n",
       " 'Castilho Sheila',\n",
       " 'Cooper Stickland Asa',\n",
       " 'Del Maksym',\n",
       " 'Hangya Viktor',\n",
       " 'Kanojia Diptesh',\n",
       " 'Heafield Kenneth',\n",
       " 'Alam Md Mahfuz Ibn',\n",
       " 'Yeganova Lana',\n",
       " 'Specia Lucia',\n",
       " \"Libovick{\\\\'y} Jind{\\\\v{r}}ich\",\n",
       " 'Freitag Markus',\n",
       " 'Behnke Maximiliana',\n",
       " 'Shang Hengchao',\n",
       " 'Wang Chenglong',\n",
       " 'Wu Kaixin',\n",
       " 'Ailem Melissa',\n",
       " 'Bak Yunju',\n",
       " 'Ballier Nicolas',\n",
       " 'Bergmanis Toms',\n",
       " 'Jon Josef',\n",
       " 'Molchanov Alexander',\n",
       " 'Pham Minh Quang',\n",
       " 'Wang Ke',\n",
       " 'Naz Sumbal',\n",
       " 'Rafieian Bardia',\n",
       " 'Wang Weixuan',\n",
       " 'Wang Xing',\n",
       " 'Yang Hao',\n",
       " 'Bi{\\\\c{c}}ici Ergun\"',\n",
       " 'Chen Yimeng',\n",
       " 'Chowdhury Shaika',\n",
       " 'Ding Shuoyang',\n",
       " '{Geigle Gregor',\n",
       " 'Heo Dam',\n",
       " 'Jiang Genze',\n",
       " 'Lim Seunghyun',\n",
       " 'Rubino Raphael',\n",
       " 'Wang Jiayi',\n",
       " 'Yankovskaya Lisa',\n",
       " 'Zerva Chrysoula',\n",
       " 'Atrio {\\\\`A}lex R.',\n",
       " '{Edman Lukas',\n",
       " \"Libovick{\\\\'y} Jind{\\\\v{r}}ich\",\n",
       " 'Khatri Jyotsana',\n",
       " 'Knowles Rebecca',\n",
       " 'Zhang Meng',\n",
       " 'Han Lifeng',\n",
       " \"Krubi{\\\\'n}ski Mateusz\",\n",
       " 'Rei Ricardo',\n",
       " 'Stefanik Michal',\n",
       " 'Takahashi Kosuke',\n",
       " 'Wan Yu',\n",
       " '{Macketanz Vivien',\n",
       " 'Behnke Maximiliana',\n",
       " 'Hu Junjie',\n",
       " 'Kumar Gaurav',\n",
       " 'Han HyoJung',\n",
       " 'Kano Yasumasa',\n",
       " 'Hwang Yongkeun',\n",
       " 'Varis Erika',\n",
       " 'Dossou Bonaventure F. P.',\n",
       " 'Gharbi Slim',\n",
       " '{H{\\\\\"a}m{\\\\\"a}l{\\\\\"a}inen Mika',\n",
       " 'Podin{\\\\u{a}} Ioana R.',\n",
       " 'Destaw Tadesse',\n",
       " 'Nakazawa Toshiaki',\n",
       " 'Nakazawa Toshiaki',\n",
       " 'Mino Hideya',\n",
       " 'Chousa Katsuki',\n",
       " 'Li Zuchao',\n",
       " 'Kondo Seiichiro',\n",
       " 'Hlaing Zar Zar',\n",
       " 'Thu Ye Kyaw',\n",
       " 'Imamura Kenji',\n",
       " 'Susanto Raymond Hendy',\n",
       " 'Park Chanjun',\n",
       " 'Ri Ryokan',\n",
       " 'Yamakoshi Takahiro',\n",
       " 'Kim Hwichan',\n",
       " 'Stribi{\\\\.z}ew Wiktor',\n",
       " 'Park Heesoo',\n",
       " 'Parida Shantipriya',\n",
       " 'Laskar Sahinur Rahman',\n",
       " 'Gain Baban',\n",
       " 'Gupta Kshitij',\n",
       " 'Zhao Yuting',\n",
       " 'Dhar Prajit',\n",
       " 'Aralikatte Rahul',\n",
       " 'Dabre Raj',\n",
       " 'Aralikatte Rahul',\n",
       " 'Kumar Sourav',\n",
       " 'Khatri Jyotsana',\n",
       " 'Dobrowolski Adam',\n",
       " 'Mhaskar Shivam',\n",
       " 'Appicharla Ramakrishna',\n",
       " 'Vegi Pavanpankaj',\n",
       " 'De Clercq Orphee',\n",
       " 'Xiang Tong',\n",
       " 'Kerz Elma',\n",
       " 'Lindow Mike',\n",
       " 'Akula Ramya',\n",
       " 'Troiano Enrica',\n",
       " 'Dayanik Erenay',\n",
       " 'Lamprinidis Sotiris',\n",
       " 'Bianchi Federico',\n",
       " 'Singh Aaditya',\n",
       " 'Tafreshi Shabnam',\n",
       " 'Kulkarni Atharva',\n",
       " 'Mundra Jay',\n",
       " 'Rao Vijjini Anvesh',\n",
       " 'Sourav Soumya',\n",
       " 'Van Hee Cynthia',\n",
       " 'Markov Ilia',\n",
       " 'Hofmann Jan',\n",
       " 'Grimminger Lara',\n",
       " 'Conforti Costanza',\n",
       " 'Ali Wazir',\n",
       " 'Wadhawan Anshul',\n",
       " 'Kaminska Olha',\n",
       " 'Kulkarni Atharva',\n",
       " 'Edmonds Darren',\n",
       " 'Guellil Imane',\n",
       " 'Culnan John',\n",
       " 'De Bruyne Luna',\n",
       " 'Vettigli Giuseppe',\n",
       " 'Fornaciari Tommaso',\n",
       " 'Butala Yash',\n",
       " 'Habash Nizar',\n",
       " 'Abdelali Ahmed',\n",
       " 'Abdul-Mageed Muhammad',\n",
       " 'Abu Farha Ibrahim',\n",
       " 'Albilali Eman',\n",
       " 'Alharbi Alaa',\n",
       " 'Alyafeai Zaid',\n",
       " 'Hakami Shatha Ali A.',\n",
       " 'Haouari Fatima',\n",
       " 'Haouari Fatima',\n",
       " 'Inoue Go',\n",
       " 'Khallaf Nouran',\n",
       " 'Majadly Muhammad',\n",
       " 'Mubarak Hamdy',\n",
       " 'Mubarak Hamdy',\n",
       " 'Mubarak Hamdy',\n",
       " 'Mulki Hala',\n",
       " 'Naous Tarek',\n",
       " 'Seelawi Haitham',\n",
       " 'Alsaleh Abdullah',\n",
       " 'Antoun Wissam',\n",
       " 'Antoun Wissam',\n",
       " 'Asaad Al-Ahmadgaid\"',\n",
       " 'Eryani Fadhl',\n",
       " 'Esmeir Saher\"',\n",
       " 'Fourati Chayma',\n",
       " 'Sheikh Ali Zien',\n",
       " 'Nguyen Minh Van',\n",
       " 'Abdul-Mageed Muhammad',\n",
       " 'AlKhamissi Badr',\n",
       " 'Althobaiti Maha J.\"',\n",
       " 'El Mekki Abdellah',\n",
       " 'Issa Elsayed',\n",
       " 'Lichouri Mohamed',\n",
       " 'Nayel Hamada',\n",
       " 'Wadhawan Anshul\"',\n",
       " 'Abu Farha Ibrahim',\n",
       " 'Abdel-Salam Reem\"',\n",
       " 'Abuzayed Abeer',\n",
       " 'Alharbi Abdullah I.',\n",
       " 'Bashmal Laila',\n",
       " '{Ghoul Dhaou',\n",
       " 'El Mahdaouy Abdelkader',\n",
       " 'Elgabry Hazem',\n",
       " 'Faraj Dalya',\n",
       " 'Gaanoun Kamel',\n",
       " 'Hengle Amey',\n",
       " 'Husain Fatemah',\n",
       " 'Israeli Abraham',\n",
       " 'Lichouri Mohamed',\n",
       " 'Naski Malek',\n",
       " 'Nayel Hamada',\n",
       " 'Song Bingyan',\n",
       " 'Wadhawan Anshul\"',\n",
       " 'Cangea C{\\\\u{a}}t{\\\\u{a}}lina',\n",
       " '{Zampieri Marcos',\n",
       " 'Chakravarthi Bharathi Raja',\n",
       " 'Khusainova Albina',\n",
       " 'Frassinelli Diego',\n",
       " 'Dunn Jonathan\"',\n",
       " 'Lameris Harm',\n",
       " 'Aly Rami',\n",
       " 'Bhatia Kushagra',\n",
       " \"Haas Ren{\\\\'e}\",\n",
       " 'Jauhiainen Tommi',\n",
       " 'Mihaela Gaman',\n",
       " 'Bestgen Yves\"',\n",
       " 'Ceolin Andrea\"',\n",
       " 'Zaharia George-Eduard',\n",
       " 'Jauhiainen Tommi',\n",
       " 'Bernier-Colborne Gabriel',\n",
       " 'Scherrer Yves',\n",
       " 'Roth Michael',\n",
       " '{Kurfal{\\\\i} Murathan',\n",
       " 'Bexte Marie',\n",
       " 'Eisenstadt Roy',\n",
       " 'Roth Michael',\n",
       " 'Ma Weicheng',\n",
       " 'Stengel-Eskin Elias',\n",
       " 'Ruby Ahmed',\n",
       " 'Wiriyathammabhum Peratham\"',\n",
       " 'de Lhoneux Miryam',\n",
       " 'Cecchini Flavio Massimiliano\"',\n",
       " 'Coto-Solano Rolando',\n",
       " 'Evang Kilian',\n",
       " 'Farris Adam',\n",
       " '{Hassert Na{\\\\\"\\\\i}ma',\n",
       " '{H{\\\\\"o}hn Georg F.K.}',\n",
       " 'Janssen Maarten\"',\n",
       " 'Kalpakchi Dmytro',\n",
       " 'Lapalme Guy\"',\n",
       " 'Lusito Stefano',\n",
       " 'Derin Mehmet Oguz',\n",
       " 'Omura Mai',\n",
       " 'Rueter Jack',\n",
       " 'Schneider Nathan',\n",
       " 'Zeman Daniel\"',\n",
       " 'Pruksachatkun Yada',\n",
       " 'Tang Zheng',\n",
       " 'Azarpanah Hossein',\n",
       " 'Feyisetan Oluwaseyi',\n",
       " 'Misra Amita',\n",
       " 'Vadrevu Samhita',\n",
       " 'Matthews Abigail',\n",
       " 'Kumar Sawan',\n",
       " 'Idahl Maximilian',\n",
       " 'Mitkov Ruslan',\n",
       " 'Sklavounou Elsa\"',\n",
       " 'Villani Rossana\"',\n",
       " 'Corpas Pastor Gloria\"',\n",
       " 'Bowker Lynne\"',\n",
       " 'Mouratidis Despoina',\n",
       " 'Saadany Hadeel',\n",
       " 'Saina Francesco\"',\n",
       " 'Murgu Dora\"',\n",
       " 'Cariello Maria Carmela',\n",
       " 'Hatami Ali',\n",
       " 'Rivera-Trigueros Irene',\n",
       " 'Rodriguez Susana',\n",
       " 'Roelofsen Floris',\n",
       " 'Ben Milad Khaled\"',\n",
       " \"Bell{\\\\'e}s-Calvera Luc{\\\\'\\\\i}a\",\n",
       " \"Venturott L{\\\\'\\\\i}gia\",\n",
       " 'Eschenbruecher Anne\"',\n",
       " 'Caro Quintana Roc{\\\\\\'\\\\i}o\"',\n",
       " 'Escribe Marie',\n",
       " 'Bestgen Yves\"',\n",
       " \"Ram{\\\\'\\\\i}rez-S{\\\\'a}nchez Gema\",\n",
       " 'Gene Viveta\"',\n",
       " 'Papadopoulou Martha Maria',\n",
       " 'Jimenez-Crespo Miguel A.\"',\n",
       " 'Charalampidou Parthena\"',\n",
       " '{Dakota Daniel',\n",
       " 'Alves Diego',\n",
       " 'Biagetti Erica\"',\n",
       " '{Grobol Lo{\\\\\"\\\\i}c',\n",
       " 'Kahane Sylvain',\n",
       " 'Kahane Sylvain',\n",
       " 'Krishnamurthy Parameswari',\n",
       " '{M{\\\\\"u}ller-Eberstein Max',\n",
       " 'Sampanis Konstantinos',\n",
       " 'van der Goot Rob',\n",
       " 'Yuan Jingting',\n",
       " 'Panchenko Alexander',\n",
       " 'Jin Yiping',\n",
       " '{Schmitt Martin',\n",
       " 'Baumgartner Matthias',\n",
       " 'Phung Duy',\n",
       " 'Zeng Qi',\n",
       " 'Gao Yanjun',\n",
       " 'Wang Luyu',\n",
       " 'Hou Xiaochen',\n",
       " 'Papagiannopoulou Eirini',\n",
       " 'Schwarzer Max',\n",
       " 'Zhao Jinman',\n",
       " 'BehnamGhader Parishad',\n",
       " 'Dutta Sanghamitra',\n",
       " 'Weber Sabine',\n",
       " 'Jha Rishi',\n",
       " 'Fujinuma Yoshinari',\n",
       " 'Thayaparan Mokanarangan',\n",
       " 'Pan Chunguang',\n",
       " 'Xiang Yuejia',\n",
       " 'Vivek Kalyan Sureshkumar',\n",
       " 'Jurgens David',\n",
       " '{Saini Rajkumar',\n",
       " 'Artemova Ekaterina',\n",
       " 'Baglini Rebekah',\n",
       " 'Amblard Maxime',\n",
       " 'Hiippala Tuomo\"',\n",
       " 'Friedrich Annemarie',\n",
       " 'Messina Lucio',\n",
       " 'Delbrouck Jean-Benoit\"',\n",
       " 'Plank Barbara\"',\n",
       " 'Jurgens David\"',\n",
       " 'Manning Emma',\n",
       " 'Smith Ronnie\"',\n",
       " 'Agirrezabal Manex\"',\n",
       " 'Madureira Brielen\"',\n",
       " 'Poliak Adam',\n",
       " 'Taneja Sanya',\n",
       " 'Durrett Greg',\n",
       " 'Gaddy David',\n",
       " 'Jurgens David\"',\n",
       " 'Foster Jennifer',\n",
       " 'Kennington Casey\"',\n",
       " 'Eisenstein Jacob\"',\n",
       " 'Schofield Alexandra',\n",
       " 'Alex Beatrice',\n",
       " 'Vajjala Sowmya\"',\n",
       " 'Pannitto Ludovica',\n",
       " 'Chaudhary Aditi',\n",
       " 'Pham MinhQuang',\n",
       " 'Gritta Milan',\n",
       " 'Roy Aurko',\n",
       " 'Luo Jiaming',\n",
       " 'Fan Angela',\n",
       " 'Pacheco Maria Leonor',\n",
       " 'Mohammadshahi Alireza',\n",
       " 'Williams Adina',\n",
       " 'Elazar Yanai',\n",
       " 'Wang Xiaozhi',\n",
       " 'Bogin Ben',\n",
       " 'Hayashi Hiroaki',\n",
       " 'Wu Zhaofeng',\n",
       " 'Prange Jakob',\n",
       " 'Park Hyunji Hayley',\n",
       " 'Angelidis Stefanos',\n",
       " 'Jacovi Alon',\n",
       " 'Xu Weijia',\n",
       " 'Luan Yi',\n",
       " 'Geva Mor',\n",
       " 'Yogatama Dani',\n",
       " 'Raghu Dinesh',\n",
       " 'Fabbri Alexander R.',\n",
       " 'Ponti Edoardo M.',\n",
       " 'Shimorina Anastasia',\n",
       " 'Choi Eunsol',\n",
       " 'Sun Zhewei',\n",
       " 'Lyu Lijun',\n",
       " 'Culkin Ryan',\n",
       " 'Puduppully Ratish',\n",
       " 'Lamont Andrew\"',\n",
       " 'Lucy Li',\n",
       " 'Liao Lizi',\n",
       " 'Hendricks Lisa Anne',\n",
       " 'Ghaddar Abbas',\n",
       " 'Wang Jianyou',\n",
       " 'Shen Aili',\n",
       " 'Zhou Meng',\n",
       " 'Liu Qi',\n",
       " 'Zmigrod Ran',\n",
       " 'Sabo Ofer',\n",
       " 'Schiffer Lena Katharina',\n",
       " 'Jo Yohan',\n",
       " '{Tang Gongbo',\n",
       " 'Stengel-Eskin Elias',\n",
       " 'Deutsch Daniel',\n",
       " 'Lamm Matthew',\n",
       " 'Peng Baolin',\n",
       " \"Gar{\\\\'\\\\i} Soler Aina\",\n",
       " 'Savoldi Beatrice',\n",
       " 'Buch Shyamal',\n",
       " 'Hahn Michael',\n",
       " 'Bareket Dan',\n",
       " 'Khattab Omar',\n",
       " 'Isonuma Masaru',\n",
       " 'Jiang Zhengbao',\n",
       " 'Bugliarello Emanuele',\n",
       " 'Udagawa Takuma',\n",
       " '{Elazar Yanai',\n",
       " 'Mou Xiangyang',\n",
       " 'Merrill William',\n",
       " 'Ganesh Prakhar',\n",
       " 'Jiang Nanjiang',\n",
       " '{Lewis Patrick',\n",
       " 'Adelani David Ifeoluwa',\n",
       " 'Deutsch Daniel',\n",
       " 'Khashabi Daniel',\n",
       " '{\\\\.Z}elasko Piotr',\n",
       " 'Begu{\\\\v{s}} Ga{\\\\v{s}}per\"',\n",
       " 'Jain Parag',\n",
       " 'Chan Hou Pong',\n",
       " '{Bisazza Arianna',\n",
       " 'Czarnowska Paula',\n",
       " 'Huang Jiayuan',\n",
       " 'Rijhwani Shruti',\n",
       " 'Kojima Noriyuki',\n",
       " 'Effland Thomas',\n",
       " 'Lakhotia Kushal',\n",
       " 'Rotman Guy',\n",
       " 'Mitropolsky Daniel',\n",
       " 'Longpre Shayne',\n",
       " '{Elazar Yanai',\n",
       " '{Schick Timo',\n",
       " 'Opitz Juri',\n",
       " 'Li Jiaoda',\n",
       " 'Freitag Markus',\n",
       " 'Narayan Shashi',\n",
       " 'Ouchi Hiroki',\n",
       " 'Lertvittayakumjorn Piyawat',\n",
       " 'Francis David',\n",
       " 'Zeng Ziheng',\n",
       " 'Pezzelle Sandro',\n",
       " 'Moosavi Nafise Sadat',\n",
       " 'Zhou Zachary',\n",
       " 'Bannour Nesrine',\n",
       " 'Soltan Saleh',\n",
       " 'Jeon Sungho',\n",
       " 'Gupta Ankit',\n",
       " 'Liu Yi',\n",
       " 'Sidiropoulos Georgios',\n",
       " 'Zhang Yue',\n",
       " 'Glenski Maria',\n",
       " 'Wang Gengyu',\n",
       " 'Torbarina Lovre',\n",
       " 'Puvis de Chavannes Lucas H{\\\\o}yberg',\n",
       " 'He Haoyu',\n",
       " 'Peng Zilun',\n",
       " 'Agrawal Ameeta',\n",
       " 'Sachidananda Vin',\n",
       " 'Gupta Ankur',\n",
       " 'Ku Lun-Wei',\n",
       " 'Pedinotti Paolo',\n",
       " 'Laverghetta Jr. Antonio',\n",
       " 'Noble Bill',\n",
       " 'Jannatus Saba Syeda',\n",
       " 'MacLaughlin Ansel',\n",
       " 'Paul Debjit',\n",
       " 'Chen Zeming',\n",
       " 'Rozen Ohad',\n",
       " 'Zarharan Majid',\n",
       " 'Grimm Frank',\n",
       " 'Indurkhya Sagar',\n",
       " 'Ou Jiefu',\n",
       " 'Cattan Arie',\n",
       " 'Pappadopulo Duccio',\n",
       " 'Kwon Heeyoung',\n",
       " 'Damonte Marco',\n",
       " 'Xia Menglin',\n",
       " 'Zhai Fangzhou',\n",
       " 'Shou Ziyi',\n",
       " 'Yamamoto Yuki',\n",
       " 'Kehat Gitit',\n",
       " 'Zhao Wei',\n",
       " 'Schlechtweg Dominik',\n",
       " '{H{\\\\\"a}tty Anna',\n",
       " 'Thorn Jakobsen Terne Sasha',\n",
       " 'Li Xiaotao',\n",
       " 'Malon Christopher\"',\n",
       " 'Caciularu Avi',\n",
       " 'Hakimi Parizi Ali',\n",
       " 'Yang Ziqing',\n",
       " 'Kozareva Zornitsa',\n",
       " 'Parnell Jacob',\n",
       " 'Rubin Ohad',\n",
       " 'Groschwitz Jonas',\n",
       " 'Kreutzer Julia',\n",
       " 'Kulikov Ilia',\n",
       " 'Dayanik Erenay',\n",
       " '{Huang Chenyang',\n",
       " 'Zhang Zhisong',\n",
       " 'Alikhani Malihe',\n",
       " 'Appelgren Mattias',\n",
       " 'Katsakioris Miltiadis Marios',\n",
       " 'Dong Tianai',\n",
       " 'Platonov Georgiy',\n",
       " 'Zhang Yue',\n",
       " 'Staniek Michael',\n",
       " 'Korpan Raj',\n",
       " 'Jeon Haein',\n",
       " 'Kulkarni Sayali',\n",
       " 'Ku Lun-Wei',\n",
       " 'Roy Shamik',\n",
       " 'Di Giovanni Marco',\n",
       " 'Kobayashi Hayato',\n",
       " 'Cao Ivy',\n",
       " 'Zhou Karen',\n",
       " 'Glenski Maria',\n",
       " 'Larimore Savannah',\n",
       " 'Mosca Edoardo',\n",
       " \"Jarqu{\\\\'\\\\i}n-V{\\\\'a}squez Horacio\",\n",
       " 'Bose Tulika',\n",
       " 'Wood-Doughty Zach',\n",
       " \"Gjurkovi{\\\\'c} Matej\",\n",
       " 'Dong MeiXing',\n",
       " 'Chen Shuguang',\n",
       " 'Oh Soyoung',\n",
       " 'Tian Yufei',\n",
       " 'Magge Arjun',\n",
       " 'Niu Jingcheng',\n",
       " 'Karisani Payam',\n",
       " '{Miranda-Escalada Antonio',\n",
       " 'Magge Arjun',\n",
       " 'Ramesh Sidharth',\n",
       " 'Sakhovskiy Andrey',\n",
       " 'Dima George-Andrei',\n",
       " 'Guo Yuting',\n",
       " 'Aji Alham Fikri',\n",
       " 'Valdes Alberto',\n",
       " 'Carreto Fidalgo David',\n",
       " \"Santamar{\\\\'\\\\i}a Carrasco Sergio\",\n",
       " 'Zhou Tong',\n",
       " 'Yaseen Usama',\n",
       " 'Kayastha Tanay',\n",
       " 'Elkaref Mohab',\n",
       " 'Blinov Pavel\"',\n",
       " 'Lee Lung-Hao',\n",
       " 'Kumar Deepak',\n",
       " \"Pach{\\\\'o}n Victoria\",\n",
       " 'Ruas Pedro',\n",
       " 'Kumar Adarsh',\n",
       " 'Laureano De Leon Frances Adriana',\n",
       " 'Pimpalkhute Varad',\n",
       " 'Luo Ying',\n",
       " 'Ji Zongcheng',\n",
       " 'Pais Vasile',\n",
       " 'Fleming Max',\n",
       " 'Mondal Anupam',\n",
       " 'Roychoudhury Rajarshi',\n",
       " 'Mesa Murgado Alberto',\n",
       " 'Cornelius Joseph',\n",
       " 'Ojha Atul Kr.',\n",
       " '{Vylomova Ekaterina',\n",
       " 'Marjou Xavier\"',\n",
       " 'Inglese Guglielmo',\n",
       " 'Iwamoto Ran',\n",
       " 'Kandula Hemanth',\n",
       " 'Choudhary Chinmay\"',\n",
       " 'Ellsworth Michael',\n",
       " 'Zhou Zhong',\n",
       " '{Hammarstr{\\\\\"o}m Harald}',\n",
       " 'Sahai Saumya',\n",
       " 'Mikhailov Vladislav',\n",
       " 'Salesky Elizabeth',\n",
       " 'Bedyakin Roman',\n",
       " 'Celano Giuseppe G. A.\"',\n",
       " 'Scherbakov Andreas',\n",
       " 'Nicolai Garrett',\n",
       " 'Roewer-Despres Francois',\n",
       " 'Dolatian Hossep',\n",
       " 'Papillon Maxime\"',\n",
       " 'Kirby James\"',\n",
       " 'Batsuren Khuyagbaatar',\n",
       " 'Jayanthi Sai Muralidhar',\n",
       " 'Vaduguru Saujas',\n",
       " 'Wiemerslage Adam',\n",
       " 'McCurdy Kate',\n",
       " 'Perkoff E. Margaret',\n",
       " 'Yang Changbing',\n",
       " 'Gerlach Andrew',\n",
       " 'Ashby Lucas F.E.',\n",
       " 'Hammond Michael\"',\n",
       " 'Lo Roger Yu-Hsiang',\n",
       " 'Gautam Vasundhara',\n",
       " 'Clematide Simon',\n",
       " 'Elsner Micha\"',\n",
       " 'Dai Huteng',\n",
       " 'Wang Yang\"',\n",
       " 'Forbes Clarissa',\n",
       " 'Ryskina Maria',\n",
       " 'Markowska Magdalena',\n",
       " 'Sharma Dravyansh',\n",
       " 'Pimentel Tiago',\n",
       " 'Ek Adam',\n",
       " \"Szolnok G{\\\\'a}bor\",\n",
       " 'Calderone Basilio',\n",
       " 'Wilson Colin',\n",
       " 'Li Haizhou',\n",
       " 'See Abigail',\n",
       " 'Ward Nigel',\n",
       " 'Kottur Satwik',\n",
       " 'Ward Nigel\"',\n",
       " 'Liang Kai-Hui',\n",
       " 'Nguyen Minh',\n",
       " 'Ravi Sujith',\n",
       " 'Heidari Peyman',\n",
       " 'Tanaka Shohei',\n",
       " 'Higashinaka Ryuichiro',\n",
       " 'Hardy Amelia',\n",
       " 'Papangelis Alexandros',\n",
       " 'Zhou Pei',\n",
       " 'Aksu Ibrahim Taha',\n",
       " 'Kottur Satwik',\n",
       " 'Shen Aili',\n",
       " 'Konigari Rachna',\n",
       " 'Xing Linzi',\n",
       " 'Miyazaki Chiaki',\n",
       " 'Zhao Tianyu',\n",
       " 'Okano Koshiro',\n",
       " 'Tian Ye',\n",
       " 'Dey Suvodip',\n",
       " 'Zhou Jingyao',\n",
       " 'Balaraman Vevake',\n",
       " 'Liesenfeld Andreas',\n",
       " 'Ishii Etsuko',\n",
       " 'Inoue Koji',\n",
       " 'Chierici Alberto',\n",
       " 'Si Wai Man',\n",
       " 'Gupta Itika',\n",
       " 'Nasreen Shamila',\n",
       " 'Ghosal Deepanway',\n",
       " 'Atwell Katherine',\n",
       " 'Qian Kun',\n",
       " 'Mahajan Khyati',\n",
       " 'Gervits Felix',\n",
       " 'Brenneis Markus',\n",
       " 'Rach Niklas',\n",
       " 'Alhindi Tariq',\n",
       " '{Do{\\\\u{g}}ru{\\\\\"o}z A. Seza',\n",
       " 'Ultes Stefan',\n",
       " '{Sch{\\\\\"u}z Simeon',\n",
       " 'Assem Haytham',\n",
       " 'Ekstedt Erik',\n",
       " 'Romero Oscar J.',\n",
       " 'Lin Hsien-chin',\n",
       " 'Liao Ling-Yen',\n",
       " 'Parthasarathi Prasanna',\n",
       " 'Parthasarathi Prasanna',\n",
       " 'Mehri Shikib',\n",
       " 'Mehri Shikib',\n",
       " 'Liu Zhengyuan',\n",
       " 'Zhuang Yingying',\n",
       " 'Manuvinakurike Ramesh',\n",
       " 'Karan Mladen',\n",
       " 'Bang Yejin',\n",
       " 'Li Haojun',\n",
       " 'Lewis Martha',\n",
       " 'Aguirre-Celis Nora',\n",
       " 'Rizzo Irene\"',\n",
       " 'Yeung Richie',\n",
       " 'Coecke Bob',\n",
       " 'Wang Daphne',\n",
       " 'Rodatz Benjamin',\n",
       " 'Duneau Tiffany\"',\n",
       " 'Widdows Dominic',\n",
       " 'Palmer Alexis',\n",
       " 'Shardlow Matthew',\n",
       " 'Taya Yuki',\n",
       " 'Martelli Federico',\n",
       " 'Zheng Boyuan',\n",
       " 'Zhang Jing',\n",
       " 'Pavlopoulos John',\n",
       " 'Dimitrov Dimitar',\n",
       " 'Feng Zhida',\n",
       " 'Meaney J. A.',\n",
       " 'Agarwal Raksha',\n",
       " 'Ortiz-Zambrano Jenny A.',\n",
       " 'Gombert Sebastian',\n",
       " 'Liebeskind Chaya',\n",
       " 'Rivas Rojas Kervy',\n",
       " 'You Huiling',\n",
       " 'Razzhigaev Anton',\n",
       " 'Zhestiankin Boris',\n",
       " 'Berend G{\\\\\\'a}bor\"',\n",
       " 'Mittal Abhishek',\n",
       " 'Liu Pingsheng',\n",
       " 'Sharma Abheesht',\n",
       " 'Xie Yuqiang',\n",
       " 'Basafa Hossein',\n",
       " 'Bansal Archit',\n",
       " 'Karimi Akbar',\n",
       " 'Paraschiv Andrei',\n",
       " 'Chhablani Gunjan',\n",
       " 'Yan Erik',\n",
       " 'Ghosh Sreyan',\n",
       " 'Wang Zhen',\n",
       " 'Ding Huiyang',\n",
       " 'Roele Cees\"',\n",
       " 'Xie Yubo',\n",
       " 'Liu Renyuan',\n",
       " 'Pang Chao',\n",
       " 'Gupta Aishwarya',\n",
       " 'Labadie Roberto',\n",
       " 'Harper Corey',\n",
       " 'Wang Nancy X. R.',\n",
       " 'Jindal Aditya',\n",
       " 'Uma Alexandra',\n",
       " '{Laparra Egoitz',\n",
       " 'Wang Weikang',\n",
       " \"{D{'}Souza Jennifer\",\n",
       " 'Liu Haoyang',\n",
       " 'Karia Neel',\n",
       " 'Pouran Ben Veyseh Amir',\n",
       " 'Lathiff Nihatha',\n",
       " 'Therien Benjamin',\n",
       " 'Zhou Yuxuan',\n",
       " '{M{\\\\\"u}ller Thomas',\n",
       " '{K{\\\\\"o}ksal Abdullatif',\n",
       " 'Kumar Harshit',\n",
       " 'Kurniawan Kemal',\n",
       " 'Yoon Sangwon',\n",
       " 'Su Xin',\n",
       " 'Shailabh Shashank',\n",
       " 'Ma Xinge',\n",
       " 'Zhang Genyu',\n",
       " 'Martin Anna',\n",
       " 'Arora Hardik',\n",
       " 'Gupta Rohan',\n",
       " 'Zhu Qinglin',\n",
       " 'Faraj Dalya',\n",
       " 'Avram Andrei-Marius',\n",
       " 'Shirude Neil',\n",
       " 'Desai Abhinandan Tejalkumar',\n",
       " 'Mosquera Alejandro\"',\n",
       " 'Vettigli Giuseppe',\n",
       " 'Xiang Rong',\n",
       " 'Bestgen Yves\"',\n",
       " 'Pan Chunguang',\n",
       " 'El Mamoun Nabil',\n",
       " 'Yuan Zheng',\n",
       " 'Huang Bo',\n",
       " 'Flynn Robert',\n",
       " 'Zaharia George-Eduard',\n",
       " 'Paetzold Gustavo Henrique\"',\n",
       " 'Rao Gang',\n",
       " 'Aziz Abdul',\n",
       " '{Smolenska Greta',\n",
       " 'Stodden Regina',\n",
       " 'King Milton',\n",
       " 'Rotaru Armand\"',\n",
       " 'Bani Yaseen Tuqa',\n",
       " 'Islam Aadil',\n",
       " 'Nandy Abhilash',\n",
       " 'Almeida Raul',\n",
       " 'Rozi Erik',\n",
       " 'Russo Irene\"',\n",
       " 'Voskoboinik Katja\"',\n",
       " 'Xie Wanying\"',\n",
       " 'Xie Shuyi',\n",
       " 'Huang Bo',\n",
       " 'Ranjbar Niloofar',\n",
       " 'Yuan Zheng',\n",
       " 'Li Wei',\n",
       " 'Goyal Harsh',\n",
       " 'Al-Hajj Moustafa',\n",
       " 'Rachinskiy Maxim',\n",
       " 'Hauer Bradley',\n",
       " 'Hettiarachchi Hansi',\n",
       " 'Davletov Adis',\n",
       " 'Bodnar Ciprian',\n",
       " 'Jiang Yuxin',\n",
       " 'Markchom Thanet',\n",
       " 'Shukla Shikhar',\n",
       " 'Xie Xin',\n",
       " 'Wang Ye',\n",
       " 'Chen Zhixiang',\n",
       " 'Ranasinghe Tharindu',\n",
       " 'Chen Ruijun',\n",
       " 'Luu Son T.',\n",
       " \"Pluci{\\\\'n}ski Kamil\",\n",
       " 'Palomino Marco',\n",
       " 'Benlahbib Abdessamad',\n",
       " 'Wang Chenyi',\n",
       " 'Suman Thakur Ashutosh',\n",
       " 'Rusert Jonathan\"',\n",
       " 'Nguyen Viet Anh',\n",
       " 'Burtenshaw Ben',\n",
       " 'Huang Bo',\n",
       " '{Delil Selman',\n",
       " 'Kotyushev Mikhail',\n",
       " 'Gia Hoang Phu',\n",
       " 'Dale David',\n",
       " 'Jain Vaibhav',\n",
       " 'Kataria Harsh',\n",
       " 'Babaei Giglou Hamed',\n",
       " 'Sharma Mayukh',\n",
       " 'Palliser-Sans Rafel',\n",
       " 'Khan Yakoob',\n",
       " 'Sat{\\\\l}awa Micha{\\\\l}',\n",
       " 'Plaza-del-Arco Flor Miriam',\n",
       " 'Hossain Tashin',\n",
       " 'Salemi Alireza',\n",
       " 'Cech Maggie\"',\n",
       " 'Zou Liang',\n",
       " 'Ghadery Erfan',\n",
       " 'Messina Nicola',\n",
       " \"Kaczy{\\\\'n}ski Konrad\",\n",
       " 'Li Peiguang',\n",
       " 'Pritzkau Albert\"',\n",
       " 'Zhu Xingyu',\n",
       " 'Singh Pranaydeep',\n",
       " 'Hou Xiaolong',\n",
       " 'Gupta Vansh',\n",
       " 'Abujaber Dia',\n",
       " 'Gupta Kshitij',\n",
       " 'Tian Junfeng',\n",
       " 'Hossain Tashin',\n",
       " \"Garc{\\\\'\\\\i}a-D{\\\\'\\\\i}az Jos{\\\\'e} Antonio\",\n",
       " 'Al Bashabsheh Emran',\n",
       " 'Guan Zhengyi',\n",
       " 'Al-Omari Hani',\n",
       " 'Yang Maoqin\"',\n",
       " 'Karasakalidis Alexandros',\n",
       " 'Song Bingyan',\n",
       " 'Essefar Kabil',\n",
       " 'Huang Bo',\n",
       " 'Sharma Mayukh',\n",
       " 'Ma Jian',\n",
       " 'Sm{\\\\u{a}}du R{\\\\u{a}}zvan-Alexandru',\n",
       " 'Mondal Anik',\n",
       " 'Zhao Yingjia',\n",
       " 'Liu Zehao',\n",
       " 'Sivanaiah Rajalakshmi',\n",
       " 'Zylich Brian',\n",
       " 'Akrah Samuel\"',\n",
       " 'Sultana Afrin',\n",
       " 'Chi Nathan',\n",
       " 'Pandey Chandan Kumar',\n",
       " 'Raha Tathagata',\n",
       " 'Samson Mihai',\n",
       " 'Gangwar Akash',\n",
       " 'Cao Jiarun',\n",
       " 'Liu Patrick',\n",
       " 'Davletov Adis',\n",
       " 'Ruan Xiaoyi',\n",
       " 'Gautam Devansh',\n",
       " 'Acharya Kaushik\"',\n",
       " 'Varma Harshit',\n",
       " 'Sun Jinquan',\n",
       " 'Yu Zhewen',\n",
       " 'Lin Jiaju',\n",
       " 'Osei-Brefo Emmanuel',\n",
       " 'Espinosa-Anke Luis',\n",
       " \"{Moreno Jos{\\\\'e} G.\",\n",
       " 'Vandenbussche Pierre-Yves',\n",
       " 'Chiarcos Christian',\n",
       " \"Moreno Jos{\\\\'e} G.\",\n",
       " 'Beltagy Iz',\n",
       " 'Augenstein Isabelle\"',\n",
       " 'Jeong Soyeong',\n",
       " 'Narimatsu Hiromi',\n",
       " 'Ozyurt Ibrahim Burak',\n",
       " 'Corvi Javier',\n",
       " 'Kontoulis Chrysovalantis Giorgos',\n",
       " 'Al Khatib Khalid',\n",
       " '{Krause Johan',\n",
       " 'Gupta Yash',\n",
       " 'Kezar Lee',\n",
       " 'Sefid Athar',\n",
       " 'Ying Senci',\n",
       " 'Kaushik Darsh',\n",
       " 'Ramirez-Orta Juan',\n",
       " 'Zeng Xia',\n",
       " 'Wadden David',\n",
       " 'Maheshwari Himanshu',\n",
       " 'Baig Yasa M.',\n",
       " 'Varanasi Kamal Kaushik',\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fd761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "197a8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above is wrong, perhaps some solution like the one here: \n",
    "# https://stackoverflow.com/questions/21421060/read-a-file-and-extract-lines-between-two-lines-of-specific-text-in-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b29a48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06559cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, 70092 rows of authors were remaining.\n"
     ]
    }
   ],
   "source": [
    "# Some cleaning\n",
    "\n",
    "minletters = 5 \n",
    "authors_clean = []\n",
    "\n",
    "for a in authors: \n",
    "    if len(a) > minletters and len(re.findall('[a-zA-Z]',a)) >0.6*len(a):\n",
    "        authors_clean.append(a) \n",
    "print(\"After cleaning, {} rows of authors were remaining.\".format(len(authors_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdb599",
   "metadata": {},
   "source": [
    "### Report the essential description of data.\n",
    "-\tDon’t print out dozens of raw lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b146649d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>5.304838</td>\n",
       "      <td>15.411135</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_count</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>29.245668</td>\n",
       "      <td>103.730310</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>5.632325</td>\n",
       "      <td>1.527317</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>1.361732</td>\n",
       "      <td>5.583222</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper</th>\n",
       "      <td>72081.0</td>\n",
       "      <td>0.081769</td>\n",
       "      <td>0.426801</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean         std   min        25%        50%  \\\n",
       "word_count  72081.0   5.304838   15.411135  1.00   4.000000   4.000000   \n",
       "char_count  72081.0  29.245668  103.730310  6.00  16.000000  19.000000   \n",
       "avg_word    72081.0   5.632325    1.527317  2.25   4.666667   5.333333   \n",
       "stopwords   72081.0   1.361732    5.583222  0.00   1.000000   1.000000   \n",
       "upper       72081.0   0.081769    0.426801  0.00   0.000000   0.000000   \n",
       "\n",
       "                  75%     max  \n",
       "word_count   4.000000   414.0  \n",
       "char_count  22.000000  2673.0  \n",
       "avg_word     6.333333    43.0  \n",
       "stopwords    1.000000   158.0  \n",
       "upper        0.000000    34.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(authors_clean, columns=['authors'])\n",
    "# Number of words\n",
    "data['word_count'] = data['authors'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['authors','word_count']]\n",
    "\n",
    "#Number of characters\n",
    "data['char_count'] = data['authors'].str.len() ## this also includes spaces\n",
    "data[['authors','char_count']]\n",
    "\n",
    "# Average word length\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['authors'].apply(lambda x: avg_word(x))\n",
    "\n",
    "# Number of stop words \n",
    "stop = stopwords.words('english')\n",
    "data['stopwords'] = data['authors'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "# Number of Uppercase words\n",
    "data['upper'] = data['authors'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "# Descriptive statistics of the DataFrame\n",
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a4bb9",
   "metadata": {},
   "source": [
    "## 3.\tModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5172eaf",
   "metadata": {},
   "source": [
    "### Prepare analytics here and construct all the data objects you will use in your report.\n",
    "•\tWrite functions and classes to simplify tasks. Do not repeat yourself.\n",
    "\n",
    "•\tAvoid output.\n",
    "\n",
    "•\tRefactor your code until it’s clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c44b635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdata(k, fname=\"data/data.txt\", report=False):\n",
    "    C_k = []\n",
    "    b = 0\n",
    "\n",
    "    for line in fname:\n",
    "        line = line.replace('\\n', '')  # remove newline symbol\n",
    "        if report:\n",
    "            print(line)\n",
    "         \n",
    "        if line != \"\":\n",
    "            # gather all items in one basket\n",
    "            C_k.append(line)\n",
    "        else:\n",
    "            # end of basket, report all itemsets\n",
    "            for itemset in itertools.combinations(C_k, k):\n",
    "                yield frozenset(itemset)\n",
    "            C_k = []\n",
    "                \n",
    "            if report:\n",
    "                print(\"\")\n",
    "\n",
    "            # report progress\n",
    "            # print every 1000th element to reduce clutter\n",
    "            if report:\n",
    "                if b % 1000 == 0:\n",
    "                    print('processing bin ', b)\n",
    "                b += 1\n",
    "\n",
    "    # last basket\n",
    "    if len(C_k) > 0:\n",
    "        for itemset in itertools.combinations(C_k, k):\n",
    "            yield frozenset(itemset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "064ebf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33590 items\n",
      "3328 items with >5 occurances\n"
     ]
    }
   ],
   "source": [
    "N = 5  # frequency threshold\n",
    "\n",
    "\n",
    "# find frequent 1-tuples (individual items)\n",
    "C1 = {}\n",
    "for key in readdata(k=1, fname=data[\"authors\"], report=False):\n",
    "    if key not in C1:\n",
    "        C1[key] = 1\n",
    "    else:\n",
    "        C1[key] += 1    \n",
    "        \n",
    "print(\"{} items\".format(len(C1)))\n",
    "\n",
    "# filter stage\n",
    "L1 = {}\n",
    "for key, count in C1.items():\n",
    "    if count >= N:\n",
    "        L1[key] = count\n",
    "print('{} items with >{} occurances'.format(len(L1), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8e6609d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0s for k=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{frozenset({'a', 'd'}): 8,\n",
       " frozenset({'d', 't'}): 8,\n",
       " frozenset({'/', 'd'}): 2,\n",
       " frozenset({'d'}): 1,\n",
       " frozenset({'.', 'd'}): 2,\n",
       " frozenset({'d', 'x'}): 2,\n",
       " frozenset({'a', 't'}): 16,\n",
       " frozenset({'a'}): 6,\n",
       " frozenset({'/', 'a'}): 4,\n",
       " frozenset({'.', 'a'}): 4,\n",
       " frozenset({'a', 'x'}): 4,\n",
       " frozenset({'/', 't'}): 4,\n",
       " frozenset({'t'}): 6,\n",
       " frozenset({'.', 't'}): 4,\n",
       " frozenset({'t', 'x'}): 4,\n",
       " frozenset({'.', '/'}): 1,\n",
       " frozenset({'/', 'x'}): 1,\n",
       " frozenset({'.', 'x'}): 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_C(k):\n",
    "\n",
    "    start = time.time()\n",
    "    C = {}\n",
    "    for key in readdata(k):  # False report\n",
    "        if key not in C:\n",
    "            C[key] = 1\n",
    "        else:\n",
    "            C[key] += 1\n",
    "    print(\"Took {}s for k={}\".format((time.time() - start), k))\n",
    "    return C\n",
    "\n",
    "get_C(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42dc1b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', \"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\")\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('Hate speech and profanity detection suffer from data sparsity, especially for languages other than English, due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. In this study, we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. This is done monolingually (German) and cross-lingually to closely-related (English), distantly-related (French) and non-related (Arabic) tasks. We observe that, on both similar and distant target tasks and across all languages, the subspace-based representations transfer more effectively than standard BERT representations in the zero-shot setting, with improvements between F1 +10.9 and F1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', \"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\")\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('We introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have curated and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the retrained version on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets, suggesting that portability is affected by compatibility of the annotated phenomena.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "(\"Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text- and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to {`}memes in the wild{'}. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that {`}memes in the wild{'} differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than {`}traditional memes{'}, including screenshots of conversations or text on a plain background. This paper thus serves as a reality-check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\", 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.', 'As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.')\n",
      "('Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('Content moderation is often performed by a collaboration between humans and machine learning models. However, it is not well understood how to design the collaborative process so as to maximize the combined moderator-model system performance. This work presents a rigorous study of this problem, focusing on an approach that incorporates model uncertainty into the collaborative process. First, we introduce principled metrics to describe the performance of the collaborative system under capacity constraints on the human moderator, quantifying how efficiently the combined system utilizes human decisions. Using these metrics, we conduct a large benchmark study evaluating the performance of state-of-the-art uncertainty models under different collaborative review strategies. We find that an uncertainty-based strategy consistently outperforms the widely used strategy based on toxicity scores, and moreover that the choice of review strategy drastically changes the overall system performance. Our results demonstrate the importance of rigorous metrics for understanding and developing effective moderator-model systems for content moderation, as well as the utility of uncertainty estimation in this domain.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.', 'Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.')\n",
      "('As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n",
      "('Social media texts such as blog posts, comments, and tweets often contain offensive languages including racial hate speech comments, personal attacks, and sexual harassment. Detecting inappropriate use of language is, therefore, of utmost importance for the safety of the users as well as for suppressing hateful conduct and aggression. Existing approaches to this problem are mostly available for resource-rich languages such as English and German. In this paper, we characterize the offensive language in Nepali, a low-resource language, highlighting the challenges that need to be addressed for processing Nepali social media text. We also present experiments for detecting offensive language using supervised machine learning. Besides contributing the first baseline approaches of detecting offensive language in Nepali, we also release human annotated data sets to encourage future research on this crucial topic.', 'Hate speech-related lexicons have been proved to be useful for many tasks such as data collection and classification. However, existing Portuguese lexicons do not distinguish between European and Brazilian Portuguese, and do not include neutral terms that are potentially useful to detect a broader spectrum of content referring to minorities. In this work, we present MIN{\\\\_}PT, a new European Portuguese Lexicon for Minorities-Related Terms specifically designed to tackle the limitations of existing resources. We describe the data collection and annotation process, discuss the limitation and ethical concerns, and prove the utility of the resource by applying it to a use case for the Portuguese 2021 presidential elections.')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for c in itertools.combinations(data[\"abstracts\"][1:8], 2):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b332254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.combinations at 0x1cab0dc1450>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itertools.combinations(data[\"abstracts\"][1:8],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d5085",
   "metadata": {},
   "source": [
    "## 4.\tResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f01788",
   "metadata": {},
   "source": [
    "•\tPrint out relevant tables nicely, display well-annotated charts and explain if needed in plain English.\n",
    "•\tUse minimum code here, just output-functions’ calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfb7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f742a3e",
   "metadata": {},
   "source": [
    "## 5.\tConclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625c661",
   "metadata": {},
   "source": [
    "•\tSummarize your findings here in 5...10 lines of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512e7d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Frequent_pairs.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76d6973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Frequent_pairs.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main e3ca8ed] renamed notebooks\n",
      " 1 file changed, 62 insertions(+), 49 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/AlexTouvras/FindingSimilarItems\n",
      "   39f59b0..e3ca8ed  main -> main\n"
     ]
    }
   ],
   "source": [
    "! git add Frequent_pairs.ipynb\n",
    "! git commit -m \"renamed notebooks\"\n",
    "! git push "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
